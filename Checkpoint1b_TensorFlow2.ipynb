{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fr39Cxns3cYv"
   },
   "source": [
    "### COMP3359 Artificial Intelligence Applications\n",
    "Department of Computer Science, HKU\n",
    "<br><br>\n",
    "\n",
    "# <u>Checkpoint 1b - TensorFlow 2</u>  \n",
    "\n",
    "## Estimated Time to Finish:   \n",
    "1~2 hours   \n",
    "\n",
    "## Main Learning Objectives:   \n",
    "-\tPractise usage of common ML framework to construct simple application.\n",
    "\n",
    "## Overview   \n",
    "1.\t[Introduction](#s1)  \n",
    "2.  [Before You Start](#2)\n",
    "3.\t[Preparation](#s3)\n",
    "4.\t[Task - Reuse Model and Make Predictions](#s2)\n",
    "5.\t[Submission](#s5)\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlHp_N0OohlG"
   },
   "source": [
    "<a id=’s1’></a>\n",
    "# 1 Introduction\n",
    "\n",
    "It may be a good idea to kick-start our study of building AI applications by learning basic usage of some ML framework. This checkpoint extends our other material \"ML Framework Learning Roadmap - TensorFlow2\". The main task in this checkpoint is to reuse the model trained in the example in \"ML Framework Learning Roadmap - TensorFlow2\", and give predictions to data we provide.  \n",
    "\n",
    "-----   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XOFPTzRtr7k"
   },
   "source": [
    "<a id=’s2’></a>\n",
    "# 2 Before You Start\n",
    "\n",
    "## Referenced Tutorial\n",
    "\n",
    "This checkpoint is mainly built by referencing the following tutorial. It is <b>strongly recommended</b> to study it once first to understand the context of this tutoiral.\n",
    "\n",
    "Referenced tutorial:\n",
    "- [TensorFlow - Basic classification: Classify images of clothing](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#scrollTo=9ODch-OFCaW4)\n",
    "\n",
    "## Auxilliary Tools\n",
    "\n",
    "In this checkpoint, you may need to use python packages to help you tackle the problems. <b>If you have no experience</b> using the following packages, it is <b>recommended</b> to check the following short tutorials and complete the simple exercises inside.\n",
    "\n",
    "- NumPy\n",
    "    - [NumPy UltraQuick Tutorial](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/numpy_ultraquick_tutorial.ipynb)\n",
    "- Pandas\n",
    "    - [Pandas DataFrame UltraQuick Tutorial](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
    "\n",
    "Since in the context of AI, we often handles a large number of numerical values that are arraged as <b>(multi-dimensional) arrays</b> (e.g. vectors, matrices, tensors), you may pay attentation to the manipulations of such (multi-dimensional) arrays in these tutorials.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meu7NxIRN1U5"
   },
   "source": [
    "<a id=’s3’></a>\n",
    "# 3 Preparation\n",
    "\n",
    "\"ML Framework Learning Roadmap - TensorFlow2\" suggests a tutorial about training an image classifier model for clothes recognition. To prepare ourselves for this checkpoint, we trained the same model here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0S-djmJK3bQB"
   },
   "outputs": [],
   "source": [
    "# Install/Upgrade to TensorFlow 2.0 if necessary\n",
    "#!pip3 install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30287,
     "status": "ok",
     "timestamp": 1610189069632,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "VfbgX7pd3jrO",
    "outputId": "83116d34-0557-4994-f0eb-dfdab8daae9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Data =====\n",
      "train_images shape (# samples, image height, image width):  (60000, 28, 28)\n",
      "train_labels shape (# samples,):  (60000,)\n",
      "test_images shape (# samples, image height, image width):  (10000, 28, 28)\n",
      "test_labels shape (# samples,):  (10000,)\n",
      "(class label, class name): \n",
      "[(0, 'T-shirt/top'), (1, 'Trouser'), (2, 'Pullover'), (3, 'Dress'), (4, 'Coat'), (5, 'Sandal'), (6, 'Shirt'), (7, 'Sneaker'), (8, 'Bag'), (9, 'Ankle boot')]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 532us/step - loss: 0.6309 - accuracy: 0.7803\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.3811 - accuracy: 0.8621\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 526us/step - loss: 0.3412 - accuracy: 0.8764\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 511us/step - loss: 0.3109 - accuracy: 0.8855\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 527us/step - loss: 0.2966 - accuracy: 0.8895\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 515us/step - loss: 0.2855 - accuracy: 0.8945\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 504us/step - loss: 0.2680 - accuracy: 0.9006\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 513us/step - loss: 0.2540 - accuracy: 0.9056\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 507us/step - loss: 0.2429 - accuracy: 0.9108\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 563us/step - loss: 0.2380 - accuracy: 0.9126\n",
      "313/313 - 0s - loss: 0.3352 - accuracy: 0.8814\n",
      "===== Model Evaluation =====\n",
      "Test accuracy: 0.8813999891281128\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Training Example Model \"\"\"\n",
    "# Ref.: TensorFlow - Basic classification: Classify images of clothing\n",
    "# https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb#scrollTo=9ODch-OFCaW4\n",
    "\n",
    "############################################\n",
    "# Please do not modify codes in this cell. #\n",
    "############################################\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "print(\"===== Data =====\")\n",
    "print(\"train_images shape (# samples, image height, image width): \", train_images.shape)\n",
    "print(\"train_labels shape (# samples,): \", train_labels.shape)\n",
    "print(\"test_images shape (# samples, image height, image width): \", test_images.shape)\n",
    "print(\"test_labels shape (# samples,): \", test_labels.shape)\n",
    "\n",
    "# Image classes\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "print(\"(class label, class name): \")\n",
    "print(list(zip(range(len(class_names)), class_names)))\n",
    "\n",
    "# Preprocess data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\"\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"===== Model Evaluation =====\")\n",
    "print(\"Test accuracy:\",test_acc)\n",
    "\n",
    "############################################\n",
    "# Please do not modify codes in this cell. #\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSMzw2Y65m97"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf2Xe5sBN6i6"
   },
   "source": [
    "<a id=’s4’></a>\n",
    "# 4 Task - Reuse Model and Make Predictions\n",
    "\n",
    "In the previous section, we have trained a model for clothes recognition. Next, we will try to reuse the trained model and make predictions on the images we provide for this checkpoint.\n",
    "\n",
    "We have prepared a data directory with few test images to be classified. The following sample codes assume the data directory is located next to this notebook, e.g.:\n",
    "```\n",
    "..\n",
    "|-- Checkpoint1_TensorFlow2.ipynb\n",
    "|-- clothes/\n",
    "  |-- img0.jpg\n",
    "  # more images…\n",
    "```\n",
    "If you put your data directory in somewhere else, you will need to modify the path to data directory accordingly below.\n",
    "\n",
    "Our task is to <u><b> make predictions on the provided images using the trained model</b></u>. More specifically, we want to print out predictions as in:\n",
    "```\n",
    "# … all preceding steps.\n",
    "# Print out predicted class names \n",
    "pred_class_names = [ class_names[pl] for pl in pred_labels ] \n",
    "print(\"Predictions: \", pred_class_names)\n",
    "```\n",
    "and your task here is to <u>complete the steps before printing out predictions</u>, which are briefly:\n",
    "1.\tLoad image data.\n",
    "2.\tPreprocess data.\n",
    "3.\tMake predictions using trained model.\n",
    "\n",
    "There are more than one way to carry out these steps and <u>you are welcomed to prepare predictions in your own fashion</u>. In case you are feeling uncertain about where to start, in the next code cell an example procedure is provided for you, and <u>you could complete the task by filling in the missing parts according to instructions given</u>. \n",
    "\n",
    "Here is an tutorial which may be helpful for you to complete this task:\n",
    "-\t[TensorFlow - Load images](https://www.tensorflow.org/tutorials/load_data/images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yh50rsSj5vDt"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for loading data if running in Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iT8P3nPj4H7l",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['Trouser', 'T-shirt/top', 'Pullover', 'Dress', 'Bag', 'Bag']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Reuse Trained Model and Make Prediction \"\"\"\n",
    "########################################################\n",
    "# This is only a suggested method to make predictions  #\n",
    "# on the provided data.                                #\n",
    "#                                                      #\n",
    "# You may modify or replace the following codes,       #\n",
    "# as long as you can provide predictions from          #\n",
    "# the trained model.                                   #\n",
    "########################################################\n",
    "\n",
    "# Specify data directory \n",
    "data_dir = \"./clothes/\"\n",
    "\n",
    "# Get image paths in data_dir\n",
    "import os\n",
    "data_paths = os.listdir(data_dir)\n",
    "data_paths = [ os.path.join(data_dir, p) for p in data_paths ]\n",
    "\n",
    "##### Load Images #####\n",
    "# Load all images into one big tensor\n",
    "image_batch = []\n",
    "for path in data_paths :\n",
    "  # Load image file into a tensor. You may try:\n",
    "  #   tf.keras.preprocessing.image.load_img: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img?version=stable\n",
    "  #   tf.keras.preprocessing.image.img_to_array: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array?version=stable\n",
    "  # p.s. the images provided are grayscale images with shape (28,28)\n",
    "  image_tensor = keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(path, color_mode=\"grayscale\", target_size=(28,28)), data_format=None, dtype=None)\n",
    "\n",
    "\n",
    "  # Preprocess image as in the example above.\n",
    "  # Normalize RGB values from [0, 255] to [0, 1]\n",
    "  image_tensor = image_tensor / 255.0\n",
    "\n",
    "  # Store loaded image in our list\n",
    "  image_batch.append(image_tensor)\n",
    "\n",
    "\n",
    "# Pack list of image tensors as one big tensor/numpy array 'image_batch'\n",
    "# (p.s. image_batch should has shape (batch_size, image_height, image_width))\n",
    "image_batch = (np.expand_dims(image_batch,0))\n",
    "image_batch.shape = image_batch.shape[1:-1]\n",
    "\n",
    "##### Make Predictions using Trained Model #####\n",
    "# Make predictions on images in 'image_batch'\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "pred_labels=[]\n",
    "result= probability_model.predict(image_batch)\n",
    "for i in result:\n",
    "    pred_labels.append(np.argmax(i))\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Printing out predictions here is your goal of this task. #\n",
    "############################################################\n",
    "# Print out predicted class names\n",
    "pred_class_names = [ class_names[pl] for pl in pred_labels ]\n",
    "print(\"Predictions: \", pred_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LQPxLvna7mY"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ-aQnhpa8v-"
   },
   "source": [
    "<a id=’s5’></a>\n",
    "# 5 Submission\n",
    "\n",
    "\n",
    "To complete and submit your work, please submit the completed version of this notebook to Moodle. Please make sure that it can be executed without errors, and predictions from trained model are provided in clear, comprehensible fashion.\n",
    "\n",
    "\n",
    "-----\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Checkpoint1b_TensorFlow2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
