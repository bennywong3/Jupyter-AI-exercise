{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOKmoPI7L-Qv"
   },
   "source": [
    "### COMP3359 Artificial Intelligence Applications\n",
    "Department of Computer Science, HKU\n",
    "<br><br>\n",
    "\n",
    "# <u>Checkpoint 1a – Scikit-Learn</u>  \n",
    "\n",
    "## Estimated Time to Finish:   \n",
    "1~2 hours   \n",
    "\n",
    "## Main Learning Objectives:   \n",
    "-\tPractise usage of common ML framework to construct simple application.\n",
    "\n",
    "## Overview   \n",
    "1.\t[Introduction](#s1)  \n",
    "2.\t[Before You Start](#s2)\n",
    "3.\t[Preparation](#s3)\n",
    "4.\t[Task - Reuse Model and Make Predictions](#s4)\n",
    "5.\t[Submission](#s5)\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3hqX5vHkjpZ"
   },
   "source": [
    "<a id=’s1’></a>\n",
    "# 1 Introduction\n",
    "\n",
    "It may be a good idea to kick-start our study of building AI applications by learning basic usage of some ML framework. This checkpoint extends our other material \"ML Framework Learning Roadmap – Scikit-Learn\". The main task in this checkpoint is to reuse the model trained in the example in \"ML Framework Learning Roadmap - Scikit-Learn\", and give predictions to data we provide.  \n",
    "\n",
    "-----   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_Hl5NE2kXuO"
   },
   "source": [
    "<a id=’s2’></a>\n",
    "# 2 Before You Start\n",
    "\n",
    "## Referenced Tutorial\n",
    "\n",
    "This checkpoint is mainly built by referencing the following tutorial. It is <b>strongly recommended</b> to study it once first to understand the context of this tutoiral.\n",
    "\n",
    "Referenced tutorial:\n",
    "- [Introduction to Python Scikit-learn](https://intellipaat.com/blog/tutorial/python-tutorial/scikit-learn-tutorial/)\n",
    "\n",
    "## Auxilliary Tools\n",
    "\n",
    "In this checkpoint, you may need to use python packages to help you tackle the problems. <b>If you have no experience</b> using the following packages, it is <b>recommended</b> to check the following short tutorials and complete the simple exercises inside.\n",
    "\n",
    "- NumPy\n",
    "    - [NumPy UltraQuick Tutorial](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/numpy_ultraquick_tutorial.ipynb)\n",
    "- Pandas\n",
    "    - [Pandas DataFrame UltraQuick Tutorial](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
    "\n",
    "Since in the context of AI, we often handles a large number of numerical values that are arraged as <b>(multi-dimensional) arrays</b> (e.g. vectors, matrices, tensors), you may pay attentation to the manipulations of such (multi-dimensional) arrays in these tutorials.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMBHPVLlen0o"
   },
   "source": [
    "<a id=’s3’></a>\n",
    "# 3 Preparation\n",
    "\n",
    "\"ML Framework Learning Roadmap – Scikit-Learn\" suggests a tutorial about training a classifier of iris species. To prepare ourselves for this checkpoint, we trained the same model here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1610188254763,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "CdOzuWY8k20L",
    "outputId": "58bafa95-403b-4914-e15e-8327267a511d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Data =====\n",
      "Example input data:\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "Example labels: \n",
      "['setosa' 'setosa' 'setosa']\n",
      "===== Data Processing =====\n",
      "Example label-encoded labels: \n",
      "[0 0 0]\n",
      "Example input data (with only selected features):\n",
      "   petal_length  petal_width\n",
      "0           1.4          0.2\n",
      "1           1.4          0.2\n",
      "2           1.3          0.2\n",
      "Example input data (vertorized):\n",
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]]\n",
      "===== Train/Test Split =====\n",
      "# input features:  2\n",
      "Shape of features_train (# samples, # features):  (120, 2)\n",
      "Shape of labels_train (# samples,):  (120,)\n",
      "Shape of features_test (# samples, # features):  (30, 2)\n",
      "Shape of labels_test (# samples,):  (30,)\n",
      "===== Model Evaluation =====\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Referenced tutorial:\n",
    "# https://intellipaat.com/blog/tutorial/python-tutorial/scikit-learn-tutorial/\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "### Preparing Dataset ###\n",
    "print(\"===== Training Data =====\")\n",
    "# Load dataset\n",
    "dfiris = sns.load_dataset(\"iris\")\n",
    "print(\"Example input data:\")\n",
    "print(dfiris.head(3))\n",
    "\n",
    "# Get data labels\n",
    "labels = np.asarray(dfiris.species)\n",
    "print(\"Example labels: \")\n",
    "print(labels[:3])\n",
    "\n",
    "### Data Preprocessing ###\n",
    "print(\"===== Data Processing =====\")\n",
    "# Convert class strings to integer labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "print(\"Example label-encoded labels: \")\n",
    "print(labels[:3])\n",
    "# Drop unnecessary features\n",
    "df_selected1 = dfiris.drop(['sepal_length', 'sepal_width', \"species\"], axis=1)\n",
    "print(\"Example input data (with only selected features):\")\n",
    "print(df_selected1.head(3))\n",
    "# Convert features to Numpy array \n",
    "df_features = df_selected1.to_dict(orient='records')\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "features = vec.fit_transform(df_features).toarray()\n",
    "print(\"Example input data (vertorized):\")\n",
    "print(features[:3])\n",
    "\n",
    "### Train/Test Split ###\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "features, labels, test_size=0.20, random_state=0)\n",
    "print(\"===== Train/Test Split =====\")\n",
    "print(\"# input features: \", features_train.shape[1])\n",
    "print(\"Shape of features_train (# samples, # features): \", features_train.shape)\n",
    "print(\"Shape of labels_train (# samples,): \", labels_train.shape)\n",
    "print(\"Shape of features_test (# samples, # features): \", features_test.shape)\n",
    "print(\"Shape of labels_test (# samples,): \", labels_test.shape)\n",
    "\n",
    "### Training Model ###\n",
    "from sklearn.svm import SVC\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(features_train, labels_train)\n",
    "\n",
    "### Model Evaluation ###\n",
    "svm_predictions = svm_model_linear.predict(features_test)\n",
    "accuracy = svm_model_linear.score(features_test, labels_test)\n",
    "print(\"===== Model Evaluation =====\")\n",
    "print(\"Test accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQjwZ4_Xk3Px"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmD5O--uf4JZ"
   },
   "source": [
    "<a id=’s4’></a>\n",
    "# 4 Task - Reuse Model and Make Predictions\n",
    "\n",
    "In the previous section, we have trained a model for image recognition. Next, we will try to reuse the trained model and make predictions on the images we provide for this checkpoint.\n",
    "\n",
    "We have prepared a data directory with few test images to be classified. The following sample codes assume the data directory is located next to this notebook, e.g.:\n",
    "```\n",
    "..\n",
    "|-- Checkpoint1_Scikit-Learn.ipynb\n",
    "|-- iris_test.csv\n",
    "```\n",
    "If you put your data directory in somewhere else, you will need to modify the path to data directory accordingly below.\n",
    "\n",
    "Our task is to <u><b> make predictions on the provided data using the trained model</b></u>. More specifically, we want to print out predictions as in:\n",
    "```\n",
    "# … all preceding steps.\n",
    "# Print out predicted class names\n",
    "pred_class_names = le.inverse_transform(preds_labels)\n",
    "print(\"Predictions: \", pred_class_names)\n",
    "```\n",
    "\n",
    "and your task here is to <u>complete the steps before printing out predictions</u>, which are briefly:\n",
    "1.\tLoad data.\n",
    "2.\tPreprocess data.\n",
    "3.\tMake predictions using trained model.\n",
    "\n",
    "There are more than one way to carry out these steps and <u>you are welcomed to prepare predictions in your own fashion</u>. In case you are feeling uncertain about where to start, in the next code cell an example procedure is provided for you, and <u>you could complete the task by filling in the missing parts according to instructions given</u>. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbGaqEeDldLd"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for loading data if running in Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JKWnxfNXuaOq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['setosa' 'setosa' 'versicolor' 'versicolor' 'virginica' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Reuse Trained Model and Make Prediction \"\"\"\n",
    "########################################################\n",
    "# This is only a suggested method to make predictions  #\n",
    "# on the provided data.                                #\n",
    "#                                                      #\n",
    "# You may modify or replace the following codes,       #\n",
    "# as long as you can provide predictions from          #\n",
    "# the trained model.                                   #\n",
    "########################################################\n",
    "\n",
    "# Specify data file path\n",
    "data_path = \"./iris_test.csv\"\n",
    "\n",
    "# Read data into Pandas DataFrame\n",
    "# (you may try: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "\n",
    "my_column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "test_df = pd.DataFrame(pd.read_csv(data_path), columns=my_column_names)\n",
    "\n",
    "# Preprocess data using the same procedure in tutorial\n",
    "\n",
    "\n",
    "df_selected2 = test_df.drop(['sepal_length', 'sepal_width'], axis=1)\n",
    "\n",
    "df_features2 = df_selected2.to_dict(orient='records')\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "features2 = vec.fit_transform(df_features2).toarray()\n",
    "\n",
    "# Make predictions using trained model\n",
    "preds_labels = svm_model_linear.predict(features2)\n",
    "\n",
    "############################################################\n",
    "# Printing out predictions here is your goal of this task. #\n",
    "############################################################\n",
    "# Print out predicted class names\n",
    "pred_class_names = le.inverse_transform(preds_labels)\n",
    "print(\"Predictions: \", pred_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCdpMIE_k53H"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KhTAV8nk620"
   },
   "source": [
    "<a id=’s5’></a>\n",
    "# 5 Submission\n",
    "\n",
    "To complete and submit your work, please submit the completed version of this notebook to Moodle. Please make sure that it can be executed without errors, and predictions from trained model are provided in clear, comprehensible fashion.\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Checkpoint1a_Scikit-Learn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
