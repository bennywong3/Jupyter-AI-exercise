{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfwvTwJR9PFG"
   },
   "source": [
    "### COMP3359 Artificial Intelligence Applications  \n",
    "Department of Computer Science, HKU \n",
    "<br><br>\n",
    "# <u>Checkpoint 5: Deep Reinforcement Learning</u>\n",
    "\n",
    "## Estimated Time to Finish \n",
    "6~10 hours (excluding optional materials)\n",
    "\n",
    "## Main Learning Objectives\n",
    "- To recognize the use of Neural Network (Deep Q Network) with the purpose of Function Approximation in Deep Q Learning approach.\n",
    "- To recognize other enhancements of Deep Q Learning from traditional Q Learning, i.e., Experience Replay\n",
    "- To have experience of implementing Deep Q Learning algorithm to handle an application with continuous state space.\n",
    "\n",
    "## Overview\n",
    "1. [Introduction](#s1) \n",
    "2. [Problem Setting](#s2) \n",
    "3. [Deep Q Learning](#s3) \n",
    "4. [Task ‚Äì Implement Deep Q-Learning Model](#s4) \n",
    "5. [Submission](#s5) \n",
    "\n",
    "\n",
    "----- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6HhcL89U2pc"
   },
   "source": [
    "<a id=‚Äôs1‚Äô></a>\n",
    "\n",
    "# 1 Introduction\n",
    "\n",
    "Previously, in the main tutorial of Module 5, we have studied the use of Q Learning in learning to navigate a taxi to pick up/drop off passengers. However, the problem is quite simple that there are only 500 states in the entire state space. Therefore, it is reasonable for you to wonder if the same Q Learning method would be able to solve more complicated problems, e.g., playing video games.\n",
    "\n",
    "Unfortunately, although there are more advanced RL algorithms to play video games, it may be difficult for us to understand those algorithms if we immediately jump to there from Q Learning. As an intermediate step, this notebook introduces an example of the ‚ÄúMountain Car‚Äù problem, which involves a state space with continuous state values, which already increases the difficulty of the problem when compared to the self-driving taxi problem.\n",
    "\n",
    "This notebook introduces an enhancement of Q Learning, namely Deep Q Learning, in which a (deep) neural network called Deep Q Network is used to replace Q Table to improve its learning performance to handle more sophisticated problems.\n",
    "\n",
    "After completion of the tasks in this notebook, you would have gained the experience of implementing the Deep Q Learning algorithm, while appreciating the enhancement of RL algorithms with deep neural networks to handle more complicated applications. \n",
    "\n",
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw2uh8h-9OxC"
   },
   "source": [
    "<a id=‚Äôs2‚Äô></a>\n",
    "# 2 Problem Setting \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkQPJN6h9V20"
   },
   "source": [
    "## Environment ‚Äì Mountain Car \n",
    "\n",
    "In this study, we will consider the [‚ÄúMountain Car‚Äù]( https://gym.openai.com/envs/MountainCar-v0/) environment from OpenAI Gym. According to the description from OpenAI Gym:\n",
    "\n",
    "> A car is on a one-dimensional track, positioned between two \"mountains\". The goal is to drive up the mountain on the right; however, the car's engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum.\n",
    "\n",
    "<center><img src='./figures/mountaincar.jpg' width='50%'/></center>\n",
    "\n",
    "In this environment, the state is described by 2 values and 3 possible actions:\n",
    "\n",
    "| Index | State | Min | Max |\n",
    "|--------|-------|-------|-------|\n",
    "| 0 | Car position <br> along x-direction | -1.2 | 0.6 |\n",
    "| 1 | Car velocity | -0.07 | 0.07 |\n",
    "\n",
    "<center>State space in ‚ÄúMountain Car‚Äù environment</center>\n",
    "\n",
    "| Index | Action |\n",
    "|--------|--------|\n",
    "| 0 | Push left |\n",
    "| 1 | No push |\n",
    "| 2 | Push right |\n",
    "\n",
    "<center>Action space in ‚ÄúMountain Car‚Äù environment</center>\n",
    "<center>From: https://medium.com/@ts1829/solving-mountain-car-with-q-learning-b77bf71b1de2</center>\n",
    "\n",
    "It is noteworthy that the state space of ‚ÄúMountain Car‚Äù environment is a continuous state space, that each of the states is a real value within a continuous interval. Comparing with the ‚Äúself-driving taxi‚Äù environment we have studied before, which has a finite discrete state space with just 500 states, the ‚ÄúMountain Car‚Äù problem is comparable more difficult. If we only use Q Learning as we have attempted before, one probable problem is to describe the continuous state-action space with a discrete Q Table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG0tp0kL95e9"
   },
   "source": [
    "## Approach ‚Äì Deep Q Learning\n",
    "\n",
    "Here, we consider the method of __Deep Q Learning (DQL)__, an enhancement of Q Learning using (deep) neural network, which the network used is usually referred as __Deep Q Network (DQN)__. This checkpoint will guide you to build a DQN model to handle the ‚ÄúMountain Car‚Äù problem.\n",
    "\n",
    "As aforementioned, the ‚ÄúMountain Car‚Äù environment is provided by OpenAI Gym. Meanwhile, to construct our DQN model, we will use PyTorch in this notebook, but in general other frameworks supporting construction of neural networks are also suitable for this task.\n",
    "\n",
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmRcHGtm97No"
   },
   "source": [
    "<a id=‚Äôs3‚Äô></a>\n",
    "# 3 Deep Q Learning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AEy6qg69-9L"
   },
   "source": [
    "## Previously on Q Learning\n",
    "\n",
    "Before we start studying DQL, let‚Äôs have a revision on (traditional) Q Learning:\n",
    "\n",
    "- What Q-Learning agent learns is the expected cumulative rewards table - __Q-table__\n",
    "- Q-value of state-action pair $Q(s,a)$:\n",
    "    - __expected cumulative rewards__ of taking action $a$ at state $s$     \n",
    "    (usually, expected cumulative rewards = immediate rewards + future rewards)\n",
    "- Training of Q-Learning model:\n",
    "    1. Initialize Q-Table (all 0‚Äôs, random values, or else)\n",
    "    2. The learning agent start at the initial state $s_0$ (start of episode)\n",
    "    3. At each current state $s$, the learning agent decides to take action $a$, based on a random choice (exploration) or some Q-values ${\\rm argmax}_a(Q(s,a))$ (exploitation) \n",
    "    4. Update Q-value: $Q(s,a) \\leftarrow Q(s,a) + \\alpha (r + \\gamma \\max_{a'}(Q(s',a'))-Q(s,a))$, where $r$ is the reward received when moving from the current state to the next state.\n",
    "    5. The terminal state $s_t$ is reached (end of episode)\n",
    "    6. Repeat steps 2-5 (for a specific number of episodes, until model converges, or else)\n",
    "- After training:\n",
    "     - After iterations of updating Q-values with the update rule above, the trained Q-values will then estimate the expected cumulative rewards, as in:    \n",
    "     $Q(s,a) = r + \\gamma \\max_{a'}(Q(s',a'))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM37Xqer-6bB"
   },
   "source": [
    "## Deep Q-Learning\n",
    "\n",
    "<u>Deep Q Network</u>\n",
    "\n",
    "Recall that, in (traditional) Q Learning, the objective of training is to train Q values to accurately estimate the expected cumulative rewards of state-action pairs, so that in the equation of Q Learning,     \n",
    "\n",
    "<center>$Q(s,a) = r + \\gamma \\max_{a'}(Q(s',a'))$,</center>    \n",
    "\n",
    "left-hand side (LHS) and right-hand side (RHS) of the equation will have similar values. However, the use of discrete Q Table to represent the expected cumulative rewards may not be the most effective, especially when the state-action space is of high complexity.\n",
    "\n",
    "In DQL, $Q(s,a)$ is considered as a function, where the input of the function is a state-action pair, and the output is the corresponding expected cumulative rewards. Usually, we consider the function to have continuous input domain, so that we can handle continuous state space. \n",
    "\n",
    "By considering $Q(s,a)$ as a function, we can then train a neural network, a.k.a. __Deep Q Network (DQN)__, to predict the values of $Q(s,a)$. To train such a DQN network, network weights are trained according to the temporal difference error $\\delta$:\n",
    "\n",
    "<center>$\\delta = Q(s,a) - (r + \\gamma \\max_{a'}(Q(s',a')))$ .</center>\n",
    "\n",
    "Therefore, by minimizing the temporal difference error $\\delta$, the difference between LHS $ùëÑ(ùë†,ùëé)$ (predicted Q values) and RHS $ùëü + \\gamma\\max_{a'}(ùëÑ(ùë†‚Äô,ùëé‚Äô))$ (target Q values) of the Q Learning equation is also minimized. Consequently, the DQN will also give an accurate approximation of the expected cumulative rewards.  \n",
    "\n",
    "Note: This is an example usage of ML methods for __Function Approximation__. Here, given inputs (state-action) and outputs (rewards from the environment), we train a neural network to approximate the underlying mapping function (assuming there is one). In this case, we are trying to replace the Q Table in traditional Q Learning with a deep neural network DQN.\n",
    "\n",
    "<u>Policy/Target Deep Q Networks</u>\n",
    "\n",
    "Although our objective here is to approximate the Q Table with some deep neural network DQN, usually two neural networks are used during training instead of only one. The two DQNs involved are known as the Policy and Target networks.  \n",
    "\n",
    "As aforementioned, DQNs are trained by minimizing the temporal difference error $\\delta$:\n",
    "\n",
    "<center>$\\delta = Q(s,a) - (r + \\gamma \\max_{a'}(Q(s',a')))$ .</center>\n",
    "\n",
    "Here, if only one DQN is used, then this DQN will be used for predicting two types of Q values at the same time: 1) Q values of current state and action $Q(s,a)$, and 2) Q values of next state and the possible actions $Q(s',a')$, as in the target Q value $(r + \\gamma \\max_{a'}(Q(s',a')))$.\n",
    "\n",
    "It is noteworthy that during training the network weights of the DQN keep changing, so as the two predicted Q values. Even if we adjust the network weights in a way that makes $Q(s,a)$ closer to the target Q value $(r + \\gamma \\max_{a'}(Q(s',a')))$ at this moment, after we update the network weights according to the temporal difference error $\\delta$, next time $Q(s,a)$ has to chase after a different target Q value. This makes it harder for the DQN to converge. \n",
    "\n",
    "Therefore, two DQNs called Policy network and Target network are used instead:\n",
    "\n",
    "- Policy network: \n",
    "    - Used for predicting $Q(s,a)$, to determine action based on current state\n",
    "    - Updated at every step of training\n",
    "- Target network: \n",
    "    - Used for predicting the target Q value $(r + \\gamma \\max_{a'}(Q(s',a')))$\n",
    "    - Only updated once in a while, by copying weights of the Policy network at the moment\n",
    "\n",
    "Therefore, in between two updates of the Target network, the target Q value is fixed so the Policy Network will have a clearer target. This helps stabilize training and fosters convergence of the Policy network. \n",
    "\n",
    "<u>Experience Replay</u>\n",
    "\n",
    "Recall that, in (traditional) Q Learning we have studied before, whenever an action is taken, the rewards received are used to update the Q values. In DQL, network weights of the DQN are updated in a different way.\n",
    "\n",
    "DQL adopts the __Experience Replay__ approach. At each step, based on the state $ùë†$, action $ùëé$ is taken, reward $ùëü$ is received and the next state $ùë†‚Äô$ is observed. Usually, we call (state, action, reward, next_state) = $(s,a,r,s')$ as a transition. After recording this transition, instead of immediately using it to update DQN network weights, we first save the transition in a memory buffer. Later, training of DQN network is performed in a minibatch training fashion, that we (randomly) sample a batch of transitions from the memory buffer. Then, this batch of transitions is fed to DQN to train the network weights.\n",
    "\n",
    "There are several advantages of adopting the Experience Replay approach to update DQN network weights. However, they will not be discussed in this study (you may check the materials suggested in ‚ÄúRecommended Materials (Optional)‚Äù). To quickly summarize the advantages, Experience Replay enables more stable training of our neural network model DQN.\n",
    "\n",
    "<u>Algorithm of Deep Q Learning</u>\n",
    "\n",
    "To sum up, the algorithm of DQL is provided in this sub-section. This may help us to construct the DQN model for the ‚ÄúMountain Car‚Äù problem in upcoming sections.\n",
    "\n",
    "1. Initialize:\n",
    "    - (Deep Q-Learning) Policy DQN (to predict $Q(s,a)$)\n",
    "    - (Deep Q-Learning) Target DQN (to predict $Q(s‚Äô,a‚Äô)$), by copying initial Policy Network\n",
    "    - (Experience Replay) Memory buffer to store transitions (state, action, rewards, next state)=$(s,a,r,s')$ \n",
    "    \n",
    "2. For each episode:\n",
    "    1. (Game Starts) Initialize environment, get initial state\n",
    "    2. For each step in the episode:\n",
    "        1. (Epsilon-Greedy) Select action, by:\n",
    "            1. (Exploration) With prob. $\\epsilon$:\n",
    "                1. Take random action\n",
    "            2. (Exploitation) Otherwise (with prob. $1-\\epsilon$):\n",
    "                1. ($Q(s,a)$ for all $a$) Predict Q-values of current state (for all actions) using Policy DQN\n",
    "                2. (${\\rm argmax}_a( Q(s,a) )$ Pick action with maximum predicted Q-value\n",
    "        2. Take action $a$, get rewards $r$, update environment, get next state $s'$\n",
    "        3. (Experience Replay) Store current transition: $(s,a,r,s')$\n",
    "        4. (Experience Replay) Train Policy DQN with __a batch of transitions in memory__, by:\n",
    "            1. For each transition $(s, a, r, s‚Äô)$ in the batch:\n",
    "                1. ($Q(s,a)$) Predict __Q-value of current state-action__ using Policy DQN\n",
    "                2. ($Q(s‚Äô,a‚Äô)$ for all $a‚Äô$) Predict __Q-values of next state__  using Target DQN\n",
    "                3. Compute the __target Q-value__\n",
    "                    1. If next state $s‚Äô$ is a terminal state, target Q-value = 0\n",
    "                    2. Otherwise, target Q-value = $r + \\gamma \\max_{a'}(Q(s',a'))$\n",
    "                 4. ($Q(s,a) = r + \\gamma \\max_{a'}(Q(s',a'))$) Compute ```loss = difference between predicted Q-value (LHS) and target Q-value (RHS)```\n",
    "            2. Update Policy DQN network weights according to the losses\n",
    "        5. Once in every, say, N steps throughout the training, update Target DQN by copying network weights of Policy DQN\n",
    "        6. If terminal state is reached:\n",
    "            1. (Game Over) End of episode\n",
    "        7. Otherwise:\n",
    "            1. Continue to the next step\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqVl8Fyc_bAI"
   },
   "source": [
    "## Recommended Materials (Optional)\n",
    "\n",
    "<u>Deep Q Learning</u>\n",
    "- [RL ‚Äî DQN Deep Q-network]( https://medium.com/@jonathan_hui/rl-dqn-deep-q-network-e207751f7ae4)\n",
    "- [Guest Post: Demystifying Deep Reinforcement Learning](https://www.intel.com/content/www/us/en/artificial-intelligence/posts/demystifying-deep-reinforcement-learning.html)\n",
    "- [Qrash Course: Reinforcement Learning 101 & Deep Q Networks in 10 Minutes]( https://towardsdatascience.com/qrash-course-deep-q-networks-from-the-ground-up-1bbda41d3677)\n",
    "\n",
    "<u>Policy and Target DQNs</u>\n",
    "- [Why does DQN require two different networks?](https://ai.stackexchange.com/questions/6982/why-does-dqn-require-two-different-networks)\n",
    "- [Q-targets, Double DQN and Dueling DQN (Taking Deep Q Networks a step further)](https://theaisummer.com/Taking_Deep_Q_Networks_a_step_further/)\n",
    "    - Discusses the topic of Policy/Target DQNs in section \"Moving Q-Targets\"\n",
    "    - Also includes discussions about other enhancements of DQNs\n",
    "- [Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks and Beyond](https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df)\n",
    "    - Discusses the topic of Policy/Target DQNs in section \"Addition 3: Separate Target Network\"\n",
    "    - Also includes discussions about other enhancements of DQNs\n",
    "    \n",
    "\n",
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwn1dGcr9Ome"
   },
   "source": [
    "<a id=‚Äôs4‚Äô></a>\n",
    "# 4 Task ‚Äì Implement Deep Q-Learning Model\n",
    "\n",
    "This section will guide you to construct a DQN model for the Mountain Car problem. In the subsequent sub-sections, we will try to implement the key components of the DQN model, with explanation to their functionalities provided. However, for some of the components, the codes to implement them are not completed. Your task in this checkpoint is to complete the missing parts by following the instructions provided. The completed components by you should pass the corresponding test cases. \n",
    "\n",
    "After completing all the missing parts, you should be able to train a DQN model which will be able to drive the car from the bottom of valley up to the top of the mountain.\n",
    "\n",
    "<u>Code References</u>:\n",
    "\n",
    "The following codes are developed while referencing the following materials:\n",
    "- [Getting Started with Reinforcement Learning and Open AI Gym]( https://towardsdatascience.com/getting-started-with-reinforcement-learning-and-open-ai-gym-c289aca874f)\n",
    "- [REINFORCEMENT LEARNING (DQN) TUTORIAL | PyTorch]( https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAtvxxNoAtof"
   },
   "source": [
    "## Before You Start\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZ9jvPqxD3x3"
   },
   "source": [
    "<u>Google Colab</u>\n",
    "\n",
    "If you would like to run this notebook on Google Colab with GPU runtime, you may set it at:\n",
    "\n",
    "Toolbar > Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "\n",
    "<u>Game Screen Display on Server</u>\n",
    "\n",
    "By default, when one tries to get the game screen of the current state of the environment using ```env.render(‚Ä¶)```, OpenAI Gym needs a window to display the image. However, if you run the codes on devices hosted on a server, e.g., Google Colab, there is no window/screen to display the image, causing errors while running the codes. \n",
    "\n",
    "In order to get the game screen and display it in a notebook running on a hosted device, you will need to install the package ```Xvfb``` using the following codes. Then, prepare a virtual display at the very beginning, so that later when ```env.render(‚Ä¶)``` is executed, the game screen can be captured and displayed in the notebook. \n",
    "\n",
    "\n",
    "Note 1: This method may not be applicable to HKU CS GPU Farm, due to the lack of authority to install ```Xvfb``` on the hosted device.\n",
    "\n",
    "Note 2: Even if the packages are properly installed in the previous code cell, you may still receive the following message:\n",
    "\n",
    "```xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\"```. \n",
    "\n",
    "The subsequent codes can still be executed without errors, so you may kindly ignore this message and proceed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "daB4c7Qn-KrL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Preparation for Display on Server '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Preparation for Display on Server \"\"\"\n",
    "#!apt-get install -y xvfb \n",
    "#!pip install pyvirtualdisplay piglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G9Kh3Jgj-O20"
   },
   "outputs": [],
   "source": [
    "# To display game screen in this notebook on a server,\n",
    "# execute these first to prepare a virtual display.\n",
    "\n",
    "# Even if the packages are properly installed in the previous code cell, \n",
    "# you may still receive the following message:\n",
    "#    \"xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\"\n",
    "# The subsequent codes can still be executed without errors, so you may kindly\n",
    "# ignore this message and proceed.\n",
    "\n",
    "#from pyvirtualdisplay import Display\n",
    "#display = Display(visible=0, size=(1400, 900))\n",
    "#display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwRJa7QdE18N"
   },
   "source": [
    "<u>HKU CS GPU Farm</u>\n",
    "\n",
    "It is __not suggested__ to run this notebook on HKU CS GPU Farm. The method mentioned above may not be applicable to HKU CS GPU Farm, due to the lack of authority to install Xvfb on the hosted device. Since the function ```env.render(...)``` is used to get the environment state throughout this notebook, the codes may result in error on GPU Farm.\n",
    "\n",
    "\n",
    "<u>Prerequisite Libraries</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y1KBf6mNA27T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.17.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from gym==0.17.1) (1.15.0)\n",
      "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gym==0.17.1) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from gym==0.17.1) (1.5.2)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gym==0.17.1) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gym==0.17.1) (1.19.2)\n",
      "Requirement already satisfied: future in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.1) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Install Prerequisite Libraries \"\"\"\n",
    "!pip3 install gym==0.17.1\n",
    "#!pip3 install torch==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyBiYLrlExkA"
   },
   "source": [
    "<u>Libraries to be used</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5WiMhOXAEyYF"
   },
   "outputs": [],
   "source": [
    "\"\"\" Libraries to be used \"\"\"\n",
    "import random\n",
    "# PyTorch for DQN model\n",
    "import torch\n",
    "# OpenAI Gym for Mountain Car environment\n",
    "import gym\n",
    "\n",
    "# Matplotlib for visualization \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"   # Set plots to have white background "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_PBzHr4EzZX"
   },
   "source": [
    "<u>Global Variables</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 1252,
     "status": "ok",
     "timestamp": 1585004835508,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "wXA40KIiE0AM",
    "outputId": "30102289-d6bc-4e98-d2b1-5f047c82f3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Parameters:\n",
      "\n",
      "PARAMS[\"ENV_NAME\"] = MountainCar-v0\n",
      "PARAMS[\"N_STATES\"] = 2\n",
      "PARAMS[\"N_ACTIONS\"] = 3\n",
      "PARAMS[\"GAMMA\"] = 0.99\n",
      "PARAMS[\"LR\"] = 0.001\n",
      "PARAMS[\"LAMBDA\"] = 0.0001\n",
      "PARAMS[\"TARGET_UPDATE_PER_STEPS\"] = 800\n",
      "PARAMS[\"MEM_BUFFER_SIZE\"] = 33590\n",
      "PARAMS[\"BATCH_SIZE\"] = 50\n",
      "PARAMS[\"EPS_START\"] = 1\n",
      "PARAMS[\"EPS_END\"] = 0.01\n",
      "PARAMS[\"EPS_DECAY_STEPS\"] = 10000\n",
      "PARAMS[\"N_EPISODES\"] = 1500\n",
      "PARAMS[\"MAX_STEP_PER_EPISODE\"] = 200\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Experiment Parameters \"\"\"\n",
    "############################################################\n",
    "# You may modify the values of parameters in this cell.    #\n",
    "# However, the following values are selected in a way that #\n",
    "# an improvement of DQN model performance will be observed #\n",
    "# during training phase, if the upcoming tasks in this     #\n",
    "# checkpoint are to completed appropriately.               #\n",
    "#                                                          #\n",
    "# Therefore, it is not suggested to modify the values,     #\n",
    "# unless you have found it impossible to complete the      #\n",
    "# tasks without changing the values.                       #\n",
    "############################################################\n",
    "\n",
    "# Store parameters in a python dict for later use\n",
    "PARAMS = {}\n",
    "\n",
    "##### MountainCar Environment #####\n",
    "# ENV_NAME: name of Mountain Car environment in OpenAI Gym\n",
    "# N_STATES: number of states in Mountain Car environment\n",
    "# N_ACTIONS: number of possible actions in Mountain Car environment\n",
    "PARAMS[\"ENV_NAME\"] = 'MountainCar-v0'\n",
    "PARAMS[\"N_STATES\"] = 2\n",
    "PARAMS[\"N_ACTIONS\"] = 3\n",
    "\n",
    "##### DQN Model #####\n",
    "# GAMMA: discount rate of expected cumulative rewards, \n",
    "#        as in Q(s,a) = r + GAMMA * max_a'( Q(s',a') )\n",
    "# LR: learning rate of DQN model\n",
    "# LAMBDA: weight for regularization of network weights (as in \"weight_dacay\" parameter \n",
    "#         in PyTorch's Adam optimizer). Regularization is applied to avoid network weights \n",
    "#         have large values, and try to prevent overfitting of the model.\n",
    "# TARGET_UPDATE_PER_STEPS: Target DQN will be updated every TARGET_UPDATE_PER_STEPS\n",
    "#                          in training phase.\n",
    "PARAMS[\"GAMMA\"] = 0.99\n",
    "PARAMS[\"LR\"] = 0.001\n",
    "PARAMS[\"LAMBDA\"] = 0.0001\n",
    "PARAMS[\"TARGET_UPDATE_PER_STEPS\"] = 800\n",
    "\n",
    "##### Experience Replay #####\n",
    "# MEM_BUFFER_SIZE: max number of transitions to store in memory buffer\n",
    "# BATCH_SIZE: batch size of transitions to be sampled during Experience Replay,\n",
    "#             i.e. DQN training data input batch size\n",
    "PARAMS[\"MEM_BUFFER_SIZE\"] = 33590\n",
    "PARAMS[\"BATCH_SIZE\"] = 50\n",
    "\n",
    "##### (Decaying) Epsilon Greedy #####\n",
    "# In this notebook, linear epsilon decay is adopted, so epsilon will just decay\n",
    "# from EPS_START down to EPS_END linearly in EPS_DECAY_STEPS steps.\n",
    "# EPS_START: starting value of epsilon\n",
    "# EPS_END: min value of epsilon\n",
    "# EPS_DECAY_STEPS: number of steps for epsilon to decay from EPS_START to EPS_END.\n",
    "#                  make sure there will be many enough steps for the model to explore \n",
    "#                  at the beginning of training.\n",
    "PARAMS[\"EPS_START\"] = 1\n",
    "PARAMS[\"EPS_END\"] = 0.01\n",
    "PARAMS[\"EPS_DECAY_STEPS\"] = 10000\n",
    "\n",
    "##### Episodic Training #####\n",
    "# N_EPISODES: number of episodes to train the DQN model\n",
    "# MAX_STEP_PER_EPISODE: if the number of steps in an episode exceeds this number, \n",
    "#                       the episode will end and the environment will reset to start\n",
    "#                       the next episode\n",
    "PARAMS[\"N_EPISODES\"] = 1500\n",
    "PARAMS[\"MAX_STEP_PER_EPISODE\"] = 200\n",
    "\n",
    "# Printing out the values of all parameters (may not be ordered)\n",
    "print(\"Experiment Parameters:\")\n",
    "print()\n",
    "for key,item in PARAMS.items() :\n",
    "    print(\"PARAMS[\\\"{}\\\"] = {}\".format(key,item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIJeaB97CKmJ"
   },
   "source": [
    "## OpenAI Gym Mountain Car Environment\n",
    "\n",
    "Here, we will prepare the Mountain Car environment for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "executionInfo": {
     "elapsed": 1427,
     "status": "ok",
     "timestamp": 1584992068745,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "h-Ep9Fxwdmd5",
    "outputId": "c9c74b8a-b3dd-42df-cc41-9b5c163de036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space:  Box(2,)\n",
      "State: (x,v) = (position along x-direction, car velocity)\n",
      "Initial state: \n",
      "[-0.49740245  0.        ]\n",
      "-----\n",
      "Action space Discrete(3)\n",
      "Possible actions: {0 (Push left), 1 (No push), 2 (Push right)}\n",
      "5 example actions: \n",
      "[1, 2, 1, 2, 1]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Prepare Mountain Car Environment \"\"\"\n",
    "# Make a new MountainCar environment\n",
    "env_name = PARAMS[\"ENV_NAME\"]\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# Description of MountainCar environment\n",
    "print(\"State space: \", env.observation_space)\n",
    "print(\"State: (x,v) = (position along x-direction, car velocity)\")\n",
    "init_state = env.reset()           # Get initial state\n",
    "print(\"Initial state: \")\n",
    "print(init_state)\n",
    "print(\"-----\")\n",
    "print(\"Action space\", env.action_space)\n",
    "print(\"Possible actions: {0 (Push left), 1 (No push), 2 (Push right)}\")\n",
    "print(\"5 example actions: \")\n",
    "print([ env.action_space.sample() for _ in range(5) ])\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 2208,
     "status": "ok",
     "timestamp": 1584859348199,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "HQwAytqVJZG3",
    "outputId": "e58023ca-0b13-426e-969f-b09e2e32ad36"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAADnCAYAAABBu67aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAh8ElEQVR4nO3deVyN+eIH8M85rQxla4gpZBsNIlsYxjqUbaQoUvYkhqGxXZl7cQ2yXFtZZkwKRYt9u0ZDiHCzx6gZmUtZWkjaz3l+f7j1s2t5Ts9ZPu/Xa/6pznk+YT7n+3y/z/N9ZIIgCCAionKTSx2AiEhbsFCJiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUinbB9+xZcvvw1MjOP48WL/yAnJx5i716qL+q7ERGpqbt3E2FufhxK5XEAgJ5eNZiY9AUAVKnSBaam/QEABgZ1IJdXLtMxWKhEpJMUiqfIyNgFAMjICMP9+zMBAKamA2FoaAG5vBLMzX1LVa4sVCIiyFA0AyqTGUAmM4RMZljqd2GhEpEOkkFPr1rxaf7LU34HAIC+vhnk8kplelcWKhHpBJlMHyYmvdG06Tzo6dWAXG4MI6OmkMlkoh2DhUpEOkEu/wRWVqGoWrWm6o6hsncmItIxLFQiIpGwUImIRMJCJSISCQuViEgkLFQiIpGwUImIRMJCJSISCQuViEgkLFQiIpGwUImIRMJCJSISCQuViEgkLFQiIpGwUImIRMJCJSISCQuViEgkLFQiIpGwUImIRMJnShGR1snOzkZWVhYA4NGjR9i0aRMuXbqEP/74A8bGxh99/ZAhQ9CqVSsAgLGxMUxMTEp0XJkgCELZYxMRSU+hUCAvLw/Hjh3DzZs38Z///Ae//vorAECpVCI7O7tU72dsbAx9/ZfjTWtrawwcOBCffvop3NzcAACVK1d+5+tYqESkkQRBQHx8PM6fP4+kpCRs3boVGRkZyMnJAYDix0PXqFEDgwYNKtXjoqOjo/HHH3+8diwDAwOYmZkBAB48ePDO1/GUn4g0yvPnz3Hq1CkcPXoUERERePjwYfH3bGxs8Nlnn6FLly4YNGgQAMDIyAiNGjUqVaHev38fz549AwBcuXIFISEhyMzMxOnTpz/4Oo5QiUjtCYKAK1euID4+HqtWrUJcXBwAoHbt2mjYsCGsrKzg6emJZs2aoXbt2irJkJWVVXzcbt26vfNnWKhEpLYKCwtx+/ZtLF26FHv37sWLFy9gaGiI+vXro2/fvhg3bhxsbGwAoFQjUFVhoRKR2snPz8edO3fg5+eH0NBQ5Ofno2bNmmjUqBG+++47ODk5QS6XQy5Xrys/WahEpDYEQcD169exYcMGbN++HTk5OTAxMcGECRMwdepU1KpV670r7OqAhUpEkhMEAfn5+di9ezcWLlyIxMRE1KhRA6NGjcKMGTNQr1496OnpSR3zo1ioRCS506dPw9vbG/Hx8TAzM4OzszOmTZsGKysrtZgbLSleNkVEksnMzISPjw/279+PJ0+eoF27dvDz83vvKrq6U68ZXSLSCYIg4ODBgxgwYAC2bNkCExMThIWFITo6WmPLFOApPxFVsPT0dCxevBiBgYHIysqCt7c3JkyYgObNm2vU6f278JSfiCqEUqlEamoqRo8ejaNHj6JFixaYOnUqxowZU3zfvKbjCJWIVE4QBOzYsQM+Pj7IyMjAsGHDsGDBAjRp0kTqaKLSjo8FIlJrO3bsgJeXFwoKCuDn54fJkydrzaj0Vdr3GxGR2khJScHkyZNx4sQJ2NraYvny5WjXrp1GXFNaFixUIlKJ5ORkDB8+HGfOnEG3bt0QGhoKc3NzqWOpFC+bIiJRFRYWYvPmzRg8eDAuX76MxYsX60SZAhyhEpGIFAoF/P394ePjAwMDA2zatAkjRoxQu01MVEU3fksiUjlBEODv749Zs2ahU6dO+Pnnn+Hq6qozZQrwsikiEoEgCFi/fj1mz56Nnj17IigoCDVq1JA6VoXTnY8OIlIJhUKBdevWYfbs2ejVqxe2bdumk2UKcA6ViMohISEBs2bNwpEjR9CnTx8EBgaiZs2aUseSDAuViMokISEBQ4YMQXx8PBwcHHR6ZFqEp/xEVCbz589HcnIyfvjhB52dM30TR6hEVGKCICApKQnHjh3DkydPEBwcDHt7e51ayf8QFioRlVhSUhKGDh2KpKQkBAUFwcHBQeO33BMTP1aIqEQSExPh6OiIe/fuYdu2bRgwYADL9A0coRLRRyUkJGDo0KG4f/8+tm3bhoEDB0odSS2xUInog4pW85OTkxEcHAwHBwepI6ktFioRvVfRaX5ycjK2b98Oe3t7nuZ/AAuViN5JEARMnToVN27cwIoVK9CvXz+W6UdwUYqI3lJ0b/6pU6fQv39/jBkzhpdGlQBHqET0mqIt+HhvfunxI4eIihUWFmLDhg2YNWsWevXqhcDAQJZpKbBQiQjA/5fp999/j549e2Lbtm06vdFJWbBQiQgKheK1kWlwcDBHpmXADaaJCBcvXsSXX34JU1NTXL9+HbVr15Y6kkbiCJVIx6WkpMDHxweGhoZYtWoVzMzMpI6ksbjKT6TDUlJS4OLigsuXLyMgIAAjR47ktablwEIl0lHJyckYPnw4rly5wjIVCedQiXTQ8+fPYW9vj5iYGGzduhUeHh4sUxFwDpVIxyiVSuzduxcXL15Ep06d0L9/f5apSFioRDpEEATs2LEDXl5eaNu2LXbv3s1FKBGxUIl0yPbt2+Hl5YXWrVsjPDwc9erVkzqSVvlgoZ46dQq5ubkVlYWIVCgtLQ0rV66EUqnEjBkzULduXakjaZ0PFmqPHj0wb9485OTkVFQeIlKB9PR0eHh44M6dO1i+fDm++eYbqSNppQ8W6rBhw7B69WosWrSoovIQkcjS09MxatQonDhxAsuXL4e3tze34lORD/6pfvvtt6hduzZCQkJw48YN8AorIs2iVCqxYcMGHD58GH379sXkyZO5oq9CH7wOVRAEREdHY9iwYahevTr27NmDzz//nH8hRBpAEAQcPnwYo0aNQt26dbFnzx40adJE6lha7aMX9guCgNDQUIwYMQK2trY4f/48DAwMKiofEZXRwYMH4e7ujnr16iEiIgJNmzaVOpLW++hEikwmg4ODA1xcXHDjxg0sX74cBQUFFZGNiMooMzMTK1asQFZWFry9vVmmFaRE9/Kbmppi48aNEAQBCxcuhCAImDVrFgwNDVWdj4hKKTMzE97e3jh37hzmz5+P8ePHSx1JZ5TqXv6//voLrVu3xosXL3Dx4kW0atVKldmIqJQEQcDYsWMRGBiIOXPmYPHixdDT05M6ls4o1bUTFhYWCAwMRKVKleDu7o4///xTVbmIqJQEQUBMTAwOHTqExo0bw8PDg2VawUq925RSqcTBgwfh5uaGJk2aYO/evbCwsFBVPiIqofPnz2Po0KEwMDDAvn370KpVK16RU8FKfXWvXC6Hvb09unXrhri4OISFhfH6VCKJ5eXlISAgAMnJyXBxcYGNjQ3LVAJlul3CwMAAgYGB6NevH3x9fbFx40YolUqxsxFRCeTk5MDHxwc7d+7ElClTsGDBAqkj6axybTAdExODvn37wtTUFBcvXoS5ubmY2YioBObPn48lS5Zg2LBh+OWXX1CpUiWpI+msct3Q26lTJ6xbtw4ZGRlwcXFBSkqKWLmIqATi4uKwfft2mJub49tvv2WZSqzcj0BRKpUIDAzExIkT0blzZ+zbtw/Vq1cXKx8Rvcfvv/8OBwcHPH36FAcPHoSdnR3nTSVW7i1n5HI5Bg8ejLZt2+LcuXM4cuQIF6mIVEyhUCAoKAh3797FwIED0aFDB5apGhBlD6+aNWsiPDwcbdu2haenJ3bt2iXG2xLROygUCixevBgrVqzAyJEjsX79el5vqiZEfeppSEgIxowZg5YtW+LYsWOoUaOGWG9NRP+TkJCALl26QKFQ4Ndff0WbNm2kjkT/I+ous8OHD8ePP/6IGzduYNy4ccjIyBDz7Yl0XkJCApycnFBYWIht27axTNWMqIUql8sxbdo0dOjQAXv37uVF/0QiKiwsxLJly3Dt2jWMHDkS/fv3lzoSvUHUU37g5f3EiYmJcHR0REpKCnbu3Ik+ffpwwpyoHAoLC7FhwwbMmjULvXv3RnBwMKfU1JDohVrk9OnT6N69O8zNzXH9+nVeSkVUDuvWrYOPjw969uyJHTt2sEzVlMqe1NWhQwfMmTMHjx49wnfffYcXL16o6lBEWi0lJQWbNm2CgYEBpkyZwjJVYyXaYLosjIyMsGDBAty9exdBQUGoU6cOli5dqqrDEWmlos1O/vrrL2zatAn29vZSR6IPUOmzZI2MjODj44OGDRsiODgYZ86cUeXhiLSKUqnE9u3bi6fPRowYwcc/qzmVzaEWEQQBV69eRa9evWBsbIzjx4/D2tpalYck0ngKhQI7d+6El5cX2rZti9DQUG4+pAFU/nEnk8nQokULuLq64uHDh9i8eTPy8/NVfVgijfbo0SNMnz4dBQUFWLNmDctUQ6hsDvW1g+jrY+XKlVAoFMW3yfn5+fH0hegdnj17hnHjxiEzMxMrV65EixYtpI5EJaTyU/5XXb16FX379oUgCPjtt9/QvHlzXp9K9ApBELB37144Ozvjiy++wIkTJ1CrVi2pY1EJVegQ0cbGBiEhIZDJZBgyZAhu3rxZkYcnUnsHDhzAuHHj0KJFC0RERLBMNUyFn3P36NEDLi4uuHPnDlavXs35VKL/yczMxD//+U+8ePECM2fOROPGjaWORKVUIXOob1q0aBEePXqEoKAg1K9fH3PmzIGhoaEUUYjUQlZWFiZNmoQrV65g/vz5GDFihNSRqAwqdA71VY8fP0aLFi2Qnp6Oc+fOoX379lLEIJKcIAjYunUrJkyYgE6dOiE6Opr7m2ooyZbZa9WqhZ9//hlVq1bFxIkTcffuXamiEElGEATExMTA19cXVlZWCAgI4NUvGkyyESrw8h/T2rVrMX36dHz99dc4evQoV/1Jpzx9+hStW7fGvXv3EBUVhR49ekgdicpB0o9CmUwGNzc32Nvb48yZMwgICIBSqZQyElGFycnJwfz58/HgwQNMmzYNdnZ2UkeicpJ0hFokNTUVvXr1QkJCAnbs2IEhQ4ZIHYlI5RYsWIDFixfD2dkZgYGBfAS0FlCLyZpatWphxowZkMlkWL16NVJSUqSORKRScXFxCAoKgrm5OaZPn84y1RJqMUIFXu6sExgYiAkTJqBz5844cOAAqlWrJnUsItH9/vvvsLe3x9OnT3Ho0CHY2dlx7UBLqMUIFXj5PKpBgwahffv2iI2NxeHDhzmfSlpHoVAgKCgISUlJxf/eWabaQ21GqEUSExOLn+R46dIlNGvWTOJEROJQKBRYtGgRlixZAhcXFwQEBOCTTz6ROhaJSG1GqEUaNGiAhQsXoqCgALNmzUJ6errUkYhEcffuXWzcuBEmJiaYPn06y1QLqV2h6uvr49tvv8X333+P/fv3Y+rUqXwUNWm8hIQEODo6oqCgANu2bYOtra3UkUgF1K5QAUBPTw9jxoxBq1atcPToURw9epSlShqroKAAfn5+uH79OlxcXODg4CB1JFIRtZtDLSIIAv744w/069cPGRkZ2LNnD7p16yZ1LKJSCwgIwLRp09C1a1eEh4fzkepaTC1HqMDLu6gaN24MNzc3PH36FBs3bkR2drbUsYhK5cGDB9iyZQsMDQ3h5eXFMtVykmzfVxpz585FQUEBli1bBgMDAwQEBKBy5cpSxyL6qJSUFAwfPhx37tzB5s2beQegDlDbEWoRIyMjTJ48GRYWFggNDcWFCxekjkT0UYIgIDIyEmfPnkWnTp3g7OzMLfl0gNrOob4pLi4Ozs7OyMnJwa5du9C1a1epIxG9k1KpxPbt2+Ht7Y127dohJCQEderUkToWVQCNKVRBELBhwwZMnz4d3bp1w6FDh3j/M6mlJ0+ewNbWFmlpaTh27Bg//HWI2p/yF5HJZJg4cSK8vLxw+vRpzJ07F3l5eVLHInpNWloaRo0ahSdPnsDPzw9dunSROhJVII0ZoRbJzc1F+/btcevWLYSFheGbb77hvdCkFjIzMzF8+HAcP34cq1atgre3N+dNdYzGjFCLGBkZYf369ahVqxbmzp2LW7du8aJ/kpwgCIiKisKvv/4Ka2truLq6skx1kMaNUIvs2bMHjo6OaNGiBWJjY3kpFUlq3759GD16NBo0aIDw8HA0atRI6kgkAY0boRbp2bMnXF1dcefOHaxcuRL5+flSRyIdlZmZiaVLlyI7OxvTp09nmeowtb+w/31MTU2xadMmAMCiRYugVCoxd+5cGBoaSpyMdMnz588xadIkxMXFwdfXF25ublJHIglp7Cl/kUePHqFly5ZIT0/HuXPn0L59e6kjkY4QBAGBgYEYO3Ys7OzscObMGc6b6jiNPeUvYmZmhq1bt6Jq1aqYMGEC/vzzT6kjkQ4QBAFnz57FvHnz0LhxY2zevBlyucb/70TlpPEjVODlnSlr1qzBjBkz0LdvXxw5coSXUpFKPXv2DDY2Nrh37x5OnDiBnj17Sh2J1IBWfKTK5XK4u7vDwcEB0dHR8Pf356VUpDI5OTmYN28eHjx4gGnTpqFTp05SRyI1oRUj1CJpaWno0aMHEhMTERISgsGDB0sdibRMdnY2fHx88NNPP8Hb2xtLlizhLdBUTKsKFQCCgoIwefJk2NraYteuXTA3N5c6EmmRqKgo9O7dG/Xr10dcXBz3N6XXaF2hCoKA4OBgeHl5oU2bNggLC2OpUrkJgoDLly9j6NChKCgoQHh4ODp27Mi5enqNVsyhvkomk8HNzQ1ubm44e/YsFi5cCKVSKXUs0nAKhQJTpkzBvXv3sHDhQpYpvZPWFSrwcpHK19cXdnZ2CA4ORmhoKBepqMwUCgUWLlyIS5cuYdSoURg+fDjLlN5JKwsVAD777DOEh4fDxsYGkyZNws6dO1mqVGoFBQX4xz/+gaVLl8LV1RXr16/HJ598InUsUlNaN4f6pr1792LEiBFo3LgxTp48iRo1akgdiTRIfHw8OnfuDH19fURHR8Pa2lrqSKTGtHaEWmTw4MFYunQpEhISMHr0aGRkZEgdiTTE7du3i58FFRwcjObNm0sdidSc1o9QgZd3Uq1evRo+Pj4YNGgQdu/eDSMjI6ljkRp78OAB+vTpg7t37yIyMhL9+vXjvCl9lNaPUIGXi1TOzs744osvEBUVhaioKM6n0nspFAqEhobi9u3b6NOnD7766iuWKZWIThQqAFhaWiIyMhIWFhZwc3PD0aNHWar0FkEQsG7dOvztb3/DgAEDsG3bNm5eTiWmE6f8r7p27Rrs7OxQuXJlXLhwAVZWVlJHIjWhVCqxbt06zJkzB19//TUCAwN5JxSVis6MUIt8/vnn8PHxQWZmJv7+97/j+fPnUkciNZGcnAw/Pz8YGhpizpw5LFMqNY3dsb+sDA0NsWDBAsjlcvz4448AAH9/f1SpUkXiZCSl+/fvY9iwYXj27Bk2b94MOzs7qSORBtK5QgUAfX19+Pr6Ijc3F8uWLYO+vj5++uknbhCso+7fvw8nJyfcvHkTmzdvhouLCxehqEx0tkH09PTg4eEBKysrHDhwALGxsVyk0kFKpRI//PADYmNjMXr0aN5WSuWic4tSb4qLi4OjoyMKCwu5g5COeXVnMltbW+zevZs7k1G56OwItYitrS0iIiKgr68PJycnxMTESB2JKoAgCAgKCoK3tzfatWvHMiVR6PwItcj58+fRvXt31KxZE+fOnYOlpaXUkUiFTp48iYEDB8LMzAwxMTGoU6eO1JFIC+j8CLVI69atMX78eDx+/BgrV65ETk6O1JFIRdLS0rB8+XIoFAr4+Pigdu3aUkciLaGTq/zvYmxsjJUrV0Iul8Pf3x8AsGzZMhgbG0ucjMSUlpaGkSNH4tSpU1i5ciW8vLw4Z06iYaG+wsjICCtWrIAgCAgICIBMJsPy5cthaGgodTQSQVpaGkaMGFFcpp6enixTEhUL9Q2Ghobw8/ODIAjYsGEDZDIZli1bxlLVcG+OTD09PaGnpyd1LNIyXJR6j+zsbPTv3x+nT5/GmjVr4O3tLXUkKqPU1FS4u7vjt99+w4oVK+Dp6Ql9fY4lSHws1A84efIkXF1dUaVKleLHqZBmKbrW1MPDA3Z2dvjtt984L04qw0L9iOjoaLi4uKBSpUqIiIhA69atpY5EJSQIAvbt24exY8fCysoKERERqF+/vtSxSIuxUD9CEATExMTA2dkZxsbGiIyMZKlqAKVSiYMHD8Ld3R2NGjUqLlMuQpEqsVBLQBAEnD17Fs7OzqhSpQoiIyPRokUL/s+pppRKJQ4dOgR3d3fUr18fkZGR3PeWKgQv7C8BmUyGLl26YNeuXcjKysLQoUMRHx/PzVTUkCAIxSNTS0tLREREsEypwrBQS0gmk6Fr164IDQ1FZmYmhgwZgps3b0odi96wf/9+eHp6onfv3oiMjESjRo2kjkQ6hKf8ZcDVf/W0d+9ejB07Fs2aNeNqPkmCI9Qy6N69O44cOYI2bdrA0dERV65ckTqSTntzNT80NJRlSpLgCLUcYmJi4OTkxNV/CRWt5hdtFh4ZGQlLS0suGJIkOEIth06dOiEsLAy5ublwcnLCtWvXuFBVgV4t0/r16yM8PJyXRpGkWKjlIJPJ0LlzZ4SGhuLFixdwcnLi6n8FKVrN9/DwgIWFBSIiItCwYUOpY5GOY6GWU9Hqf0hICDIzM+Ho6IibN2+yVFUoNTUVmzZtKh6Z7tmzh6v5pBY4hyqiotV/AwMDDBs2DIsWLUKlSpWkjqVVUlNT4eHhgcOHD8PW1hZhYWG8zpTUBkeoIurevTt27dqFwsJCrFq1CnPmzEF2drbUsbRGWlpa8a5R3bt350X7pHZYqCLr2rUr9u3bh/Hjx8Pf3x9z585Fbm6u1LE0XtF+pkVb8J04cYIbnZDa4aaQIpPJZGjfvj1sbGxgZGQEf39/pKamYurUqXxEdRkoFApERkYiICAAMTExxZtDy+UcC5D64RyqCuXm5sLHxwf+/v6oW7cuwsPD1bpUBUGAQqF45/eePXuG3bt3Q6lUvvb1fv36qWxBqOhRz15eXlAoFFi1ahU3hya1xkJVsezsbCxevBg7duyAQqHA0qVL8c0336BKlSoVmuPVv+YzZ87g8ePHb/3MgwcPsH79+ne+vqCgAElJSW99PSwsDE5OTqLlLJKcnIxdu3bB19cXTZs2xcSJEzF+/HiWKak3gSrEpUuXhIYNGwoymUxwd3cXMjMzK/T4wcHBQseOHYWOHTsKJiYmAgBR/gsLCxM96/3794Uvv/xSACB0795dSElJEf0YRKrAiagK0rZtW0RGRqJdu3YICQmBvb09Dh06VGHXq6akpCA2NhaxsbHIzMyskGOWVmFhIdauXQt7e3tcvXoVDg4OCAkJQZ06daSORlQiLNQKZGNjg5iYGMydOxcXLlyAu7s7Dh06hOfPn0sdTXJpaWlYu3YtfHx8cPfuXWzcuBEHDhxgmZJGYaFWIJlMBn19ffj6+iIgIAB169aFo6MjRowYgcePH7+14CMmQ0NDlSyG/fvf/37vQlZJFBQU4NatW+jevTtmz56NXr16YefOnXBxceFKPmkeqeccdNnvv/8uWFtbC3p6eoKZmZmwY8cOoaCgQCXHysjIEOrVq1eu+VKZTPbW1xo3bizk5+eXOo9SqRTy8/OFBQsWCKampoJcLhcGDhwopKenq+C3J6oYHAJIqGnTpoiKisLy5cvx7NkzeHp6YsCAAXj48KHoc6uVKlWCnp5emV5rbGyM5s2bw8HBAS1btkTdunXLlSU3NxdhYWHo2LEjfvzxR+jp6SEyMhLBwcGoXr16ud6bSEq8bEoNFBYW4vLly5gxYwbOnDmDpk2bwtPTE05OTrC0tBTlGHl5eWjatCn++usvAECtWrVga2sLS0tLCIKA2NhYJCYmvnVXV8uWLfHll1/CzMyseMogOzsbCQkJOHLkCCwsLBAfHw8DA4MS5bhx4wb8/f2xadMmKJVKuLu7Y/bs2bC2thbl9ySSEgtVjSQnJyMiIgLz5s1DVlYWmjVrBg8PD8ycOROGhobleu9XC9XS0hJOTk6oWrXqaz8THx+P/fv3Iy8vDwDQsGFDDB8+HEZGRu98z/DwcOTl5X20UAVBQEJCAtasWYOIiAikpqaiZcuWmDNnDhwcHN7KQaSpeMqvRurWrYspU6YgMjISAwYMQHJyMubPnw9XV1fExsaKsifAp59++s4yBYDmzZtj4MCBxSNRMzOz95YpANjZ2X30eJmZmdi3bx/s7Ozg7++PwsJCTJs2DbGxsRg2bBjLlLQKbztRMzKZDH369MFXX32FU6dOISAgAHv27MHBgwcxdOhQtGzZEpMmTUK1atXKtGpftWrV95aYTCZDvXr1YGpqWrx59odYWFjAx8fnrbnZwsJC/Pe//8WWLVtw/vx5nD59GkZGRpg8eTK8vLzw+eef844n0ko85VdzWVlZWLZsGX7++Wc8fPgQMpkM5ubmmD59OsaOHQsTE5MSlVNeXh6sra3RoEEDdO3a9b0/Z2JigpEjR0ImkyEqKgq3b99+78/Wq1cP48ePh0wmK94HICkpCVu2bMGWLVuQkZEBuVyOL774AqGhoWjSpEmJ51qJNBELVQMIgoD79+8jICAAV69exdGjR6FUKmFpaYnmzZtj5syZ6N27NwC8d9QqCALu3buH1NRUHDx48L3Hql69OqZMmQI9PT0kJSUhJCSkeE71Tba2thg4cCDy8vKwf/9+LF26FCkpKXj48CGqVKmCvn37olevXhg6dCg+/fTT8v9BEKk5FqqGycvLw4ULF7BkyRKcPHkSubm5qFy5MqytrTFgwAB069YNtWvXfu+q+YMHDxAcHPze+VgrKyu4ublBLpdDEATs2rXrnaPU7OxstGnTBsePH8fly5dx7do1KJVK1KxZE/3798fMmTPRsmVLtd1Zi0gVWKgaSqlUIjo6GtevX8fatWuRmJhY/D1zc3PY2NigXr16mDp1KmQyGczMzGBubg4AuHXrFvbt2/dWqdavX/+tBasXL17g8OHDiIqKKv5acnIyLl68iJSUFACAnp5e8ap9o0aN0K5dO1X+6kRqi4Wq4QRBQHp6Og4dOoQjR47gzJkzyM7ORnp6OoD/nwKwtraGra1t8evu3bsHMzMzWFhYAAA6dOgAGxsbFBQU4F//+tdrt5MeP34cDx8+fO24tWvXhoGBAVxdXdG2bVsMGTIEBgYGHJGSTmOhapGCggIoFArcvn0bx44dw8OHD/HLL79AEATk5+e/NSKVy+XFBainp1e8uJSfn//az33yySfQ09ND5cqV4eXlBWNjY4wcORI1a9aEgYFBme/AItI2LFQtVlhYiGfPngEAzp07h+PHj7/2/bNnz+LatWuvfc3ExASurq6vbUzi7u6OBg0aQCaToVq1aty0hOg9WKg6LC0trbhwi+jr68PCwoKn7kRlwEIlIhIJz92IiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUiEgkLlYhIJCxUIiKRsFCJiETCQiUiEsn/Ab44Tt0y8c47AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Game Screen Display \"\"\"\n",
    "# It is also possible to get the game screen showing position of the car.\n",
    "# An RBG image frame with shape (height,width,3) is returned with mode='rgb_array'.\n",
    "# \n",
    "# Note: Running this on server without virtual display prepared may cause error.\n",
    "#       Skip this cell if the requirement is not met.\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "frame = env.render(mode='rgb_array')  \n",
    "\n",
    "# Display the frame\n",
    "plt.imshow(frame)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jDFYs8joCJV"
   },
   "source": [
    "## Deep Q Network \n",
    "\n",
    "In this study, we will experiment on a DQN model that is simply a Neural Network with 2 hidden Fully-Connected (a.k.a. Linear) layers. It is noteworthy that the DQN model takes the environment state (```in_dim=N_STATES```) as input and output the predicted Q values for all possible actions (```out_dim=N_ACTIONS```), as in ```Q(s,a) for all a```. However, the implementation of this model is left unfinished.\n",
    "\n",
    "__<u>Q1) Implement the DQN model in PyTorch according to the model structure specified below.</u>__\n",
    "\n",
    "|  | Layer Type | Input Dim. | Output Dim. |\n",
    "|--|--|--|--|\n",
    "| 1 | Linear | in_dim | 50 |\n",
    "| 2 | ReLU | | |\n",
    "| 3 | Linear | 50 | 50 |\n",
    "| 4 | ReLU | | |\n",
    "| 5 | Linear | 50 | out_dim |\n",
    "\n",
    "The completed codes should pass the following test case, so that the following criterion (or criteria) is (are) fulfilled:\n",
    "\n",
    "C1.1) Model output ```y_temp``` must have shape (1,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h69WkSYElUco"
   },
   "outputs": [],
   "source": [
    "\"\"\" Deep Q Network \"\"\"\n",
    "import torch.nn as nn\n",
    "\n",
    "# Class of DQN model\n",
    "class DQN(nn.Module) :\n",
    "    # Define model structure\n",
    "    def __init__(self, in_dim, out_dim) :\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - in_dim: dimension of input of DQN model, expected to be the \n",
    "                       number of states (N_STATES).\n",
    "        - out_dim: dimension of output of DQN model,\n",
    "                        expected to be the number of possible actions (N_ACTIONS). \n",
    "        (so outputs of DQN model will be predicted Q-Values of input state s for \n",
    "         ALL ACTIONS, i.e. for each input\n",
    "                         state s, returns a vector of Q(s,a) for all actions a)\n",
    "                        \n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # Expected input shape: (B, 2)\n",
    "        # Expected output shape: (B, 3)\n",
    "\n",
    "        # DQN Model Structure:\n",
    "        #            |            |              | Tensor Shape of   \n",
    "        # Layer Type | Input Dim. |  Output Dim. |  Layer Output   \n",
    "        # -----------|------------|--------------|-----------------\n",
    "        #  Linear    | in_dim (2) |      50      |     (B,50)\n",
    "        #  ReLU      |      -     |      -       |     (B,50)\n",
    "        #  Linear    |     50     |      50      |     (B,50)\n",
    "        #  ReLU      |      -     |      -       |     (B,50)\n",
    "        #  Linear    |     50     |  out_dim (3) |     (B,3)\n",
    "\n",
    "        # To construct your model here ...\n",
    "        self.lin1 = nn.Linear(in_dim, 50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(50, 50)\n",
    "        #self.relu2 = nn.ReLU()\n",
    "        self.lin3 = nn.Linear(50, out_dim)\n",
    "\n",
    "    # (Forward Propagation) Define how input data (x) goes through the DQN model \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input(s):\n",
    "        - x: Batch of input states, \n",
    "             with shape (batch_size, n_states)\n",
    "\n",
    "        Output(s):\n",
    "        - Predicted Q-Values of current state for all actions, \n",
    "          with shape (batch_size, n_actions)\n",
    "        \"\"\"\n",
    "        # To be completed ...\n",
    "        #print(x.shape)\n",
    "        x = self.lin1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.lin2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.lin3(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mjWJ7HwrokE6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n",
      "y_temp shape: torch.Size([1, 3]) (expected: (1,3))\n",
      "y_temp values: [[0.10625175386667252, 0.22031043469905853, 0.2943514585494995]] (can be any)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Q1 Test Case (DQN) \"\"\"\n",
    "#################################################\n",
    "# Please do not modify codes in this cell.      #\n",
    "# If the missing codes in the previous cell is  # \n",
    "# completed appropriately, you should be able   #\n",
    "# to execute this code cell without errors.     #\n",
    "#################################################\n",
    "\n",
    "##### Construct Temporary DQN Model for Testing #####\n",
    "# Input dim\n",
    "policy_temp = DQN(in_dim=PARAMS[\"N_STATES\"], out_dim=PARAMS[\"N_ACTIONS\"])\n",
    "\n",
    "##### Test Case #####\n",
    "# Test input state with one state: [[0.33,0.59]]\n",
    "x_temp = torch.tensor([[0.33,0.59]])   # x_temp shape: (batch_size, num_state)\n",
    "\n",
    "# Compute test model output\n",
    "y_temp = policy_temp(x_temp)  # y_temp shape: (batch_size, num_actions)\n",
    "print(\"Test results:\")\n",
    "print(\"y_temp shape: {} (expected: (1,3))\".format(y_temp.shape))\n",
    "print(\"y_temp values: {} (can be any)\".format(y_temp.tolist()))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct2wBWkmT-yG"
   },
   "source": [
    "## Experience Replay\n",
    "\n",
    "There are two things required for implementation of Experience Replay algorithm:\n",
    "\n",
    "1. Transition memory buffer to store transitions, and\n",
    "2. Main Experience Replay procedure to update network weight.\n",
    "\n",
    "Both of them have already been implemented for you in the following code cells, and there is __no missing codes in this sub-section__. The following code cells only provide the implementation codes, comments to explain code functionalities and some simple demo to illustrate how the functions work.\n",
    "\n",
    "First, the transition memory buffer is implemented as followings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SMgw2YK-T_oZ"
   },
   "outputs": [],
   "source": [
    "\"\"\" Memory Buffer of Transitions for Experience Replay \"\"\"\n",
    "# Ref.: section \"Replay Memory\" from \"PyTorch - Reinforcement Learning (DQN) Tutorial\"\n",
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html#replay-memory\n",
    "from collections import namedtuple\n",
    "import random\n",
    "\n",
    "# Transitions: a tuple with predefined field names to store a single transaction. \n",
    "#\n",
    "# For EACH transaction, the followings will be stored in each of the fields:\n",
    "# \"state\": current state, PyTorch tensor with shape (1, N_STATES) \n",
    "# \"action\": action taken, PyTorch tensor with shape (1, 1)\n",
    "# \"reward\": reward received, PyTorch tensor with shape (1)\n",
    "# \"next_state\": state after action is performed, PyTorch tensor with shape (1, N_STATES)\n",
    "#\n",
    "# Note that a \"batch dimension\" (the first dimension with value 1) is added to the tensors (except rewards)\n",
    "# so that it will be easier for us to pack a list with B transitions (each with shape, say, (1, N_STATES)))\n",
    "# into one large tensor as DQN model input (with shape, say, (B, N_STATES))\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward', 'next_state'))\n",
    "\n",
    "# ReplayMemory: a cyclic buffer to store transitions.\n",
    "# Later we will store transitions with push(...) function, and\n",
    "# randomly sample of transition batches with sample(...) function\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 1792,
     "status": "ok",
     "timestamp": 1584992156348,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "ACvf5qvsUDyC",
    "outputId": "d71e726c-6993-4a38-e7fb-3e440e13f322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example transition batch: \n",
      "[Transition(state=tensor([[0., 0.]]), action=tensor([[0]]), reward=tensor([0.]), next_state=tensor([[0., 0.]])), Transition(state=tensor([[1., 1.]]), action=tensor([[1]]), reward=tensor([1.]), next_state=None)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Demo Usage of Memory Buffer \"\"\"\n",
    "# Construct a temporary memory buffer for demo\n",
    "memory_temp = ReplayMemory(2)    # A memory buffer that can only store 2 transitions\n",
    "\n",
    "# 1st test transition \n",
    "s_temp,a_temp,r_temp,ns_temp = torch.zeros(1,2), torch.zeros(1,1).long(), torch.zeros(1), torch.zeros(1,2)\n",
    "memory_temp.push(s_temp,a_temp,r_temp,ns_temp)    # Save to memory buffer\n",
    "# 2nd test transition \n",
    "s_temp,a_temp,r_temp,ns_temp = torch.ones(1,2), torch.ones(1,1).long(), torch.ones(1), None\n",
    "memory_temp.push(s_temp,a_temp,r_temp,ns_temp)    # Save to memory buffer\n",
    "\n",
    "# Get an example transition batch with 2 transitions.\n",
    "# The returned value is a python list of 2 Transition namedtuple (state, action, reward, next_state)\n",
    "bs_temp = 2\n",
    "state_batch_temp = memory_temp.sample(bs_temp)\n",
    "print(\"Example transition batch: \")\n",
    "print(state_batch_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbUh6ff9R_kr"
   },
   "source": [
    "The next code cell shows the implementation of the main Experience Replay algorithm. It is worth emphasizing that updating of DQN model network happens at the end of this function. This means that the DQN is only trained during Experience Replay, but not at other moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "62KoJAqU5vdp"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def experience_replay(policy_net, target_net, memory, optimizer, params, DEBUG=False) :\n",
    "    \"\"\"\n",
    "    Input(s) :\n",
    "    - policy_net: Policy DQN\n",
    "    - target_net: Target DQN\n",
    "    - memory: Transition memory buffer\n",
    "    - optimizer: optimizer used by dqn model\n",
    "    - params: dictionary storing global parameters.\n",
    "              expected parameter:\n",
    "              - params[\"BATCH_SIZE\"]: input batch size\n",
    "              - params[\"GAMMA\"]: discount rate in Q(s,a) = r + gamma * max_a'( Q(s',a') )\n",
    "    - DEBUG: print debug messages if true\n",
    "    Output(s) :\n",
    "    - loss value compute from the sampled input transition batch.\n",
    "    \"\"\"\n",
    "    if DEBUG :\n",
    "        print(\"===== Start of Experience Replay =====\")\n",
    "    # Get global parameters\n",
    "    BATCH_SIZE = params[\"BATCH_SIZE\"] # Input batch size\n",
    "    GAMMA = params[\"GAMMA\"]           # Discount rate in Q(s,a) = r + gamma * max_a'( Q(s',a') )\n",
    "    \n",
    "    # Skip training DQN model if there are not enough saved transitions in the memory buffer\n",
    "    # to give a input batch.\n",
    "    if len(memory) < BATCH_SIZE :\n",
    "        # Return a loss value = 0 to notice that training is not yet started (only for logging)\n",
    "        return torch.tensor([0])\n",
    "\n",
    "    device = next(policy_net.parameters()).device # Get computation device used by DQN model\n",
    "\n",
    "    ##### Prepare Transition Data Batch #####\n",
    "    # Randomly sample BATCH_SIZE Transition tuples (state, action, reward, next_state),\n",
    "    # each of (state, action, reward, next_state) is a PyTorch tensor. \n",
    "    # Shapes of tensors (in each 4-tuple in \"transitions\"): \n",
    "    #    state: (1, N_STATES), action: (1, 1), reward: (1), next_state: (1, N_STATES)\n",
    "    # \"transitions\" is then a python list of 4-tuples with length BATCH_SIZE.\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Convert the python list of Transition tuples (\"transitions\") to one single \n",
    "    # Transititon tuple (state, action, reward, next_state) (\"batch\"). \n",
    "    # Each of (state, action, reward, next_state) in \"batch\" is a list (with length BATCH_SIZE) \n",
    "    # of tensors of that field in this data batch.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # For each list of tensors (batch.[state/action/next_state/reward]) in \"batch\",\n",
    "    # convert the list into one single tensor ([state/action/next_state/reward]_batch).\n",
    "    #\n",
    "    # torch.cat(...) is used to concatenate a list of B tensors with shape (1, N) to \n",
    "    # a tensor with shape (B, N)\n",
    "    state_batch = torch.cat(batch.state)                                                       # shape: (B, N_STATES)\n",
    "    action_batch = torch.cat(batch.action)                                                     # shape: (B, 1)\n",
    "    reward_batch = torch.cat(batch.reward)                                                     # shape: (B)\n",
    "    # Now, state_batch has the shape of input data to the DQN model.\n",
    "\n",
    "    # However, it is not enough to simply concatenate batch.next_state (list of smaller tensors) \n",
    "    # as next_state_batch (one larger tensor).\n",
    "    # This is because if the terminal state is achieved, next_state is marked as None.\n",
    "    # Also, later when we try to predict Q(s',a') for next state s', DQL is not designed to accept \n",
    "    # terminal next state, and we will just set the term \"gamma * max_a'( Q(s',a') )\" to 0.\n",
    "    #\n",
    "    # Thus, we extract the non-final next state first, which will be used to predict Q(s',a') of \n",
    "    # non-final next states later.\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])                             # shape: (B_non_final)\n",
    "    # To keep track of the non-final next states, we use a mask to mark down locations of values \n",
    "    # of non-final next states.\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "                                                                                               # shape: (B)\n",
    "    if DEBUG :\n",
    "        print(\"State batch: \\n\", state_batch)\n",
    "        print(\"Action batch: \\n\", action_batch)\n",
    "        print(\"Reward batch: \\n\", reward_batch)\n",
    "        print(\"Locations of non-final next states: \\n\", non_final_mask)\n",
    "        print(\"-----\")\n",
    "\n",
    "    ##### Deep Q Learning #####\n",
    "    # Recall the equation of Q Learning:\n",
    "    #     Q(s,a) = r + gamma * max_a'( Q(s',a') ) \n",
    "\n",
    "    ### LHS: Q(s,a) ###\n",
    "    # policy_net(state_batch) :                                                                # shape: (B, N_ACTIONS)\n",
    "    #     Policy DQN predicts Q values of current state Q(s,a) for all possible actions a.\n",
    "    # policy_net(state_batch).gather(1, action_batch): \n",
    "    #     As we are only interested in updating the Q value Q(s,a) of the taken action a,\n",
    "    #     we gather the corresponding the concerned Q value according to index of action in action_batch.\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)                      # shape: (B,1)\n",
    "    if DEBUG :\n",
    "        print(\"Predicted Q values (LHS) = Q(s,a)\")\n",
    "        print(\"= \", state_action_values)\n",
    "\n",
    "    ### RHS: r + gamma * max_a'( Q(s',a') ) ###\n",
    "    # next_state_values :\n",
    "    #     prepare a 0-value tensor for later to store the max predicted Q values max_a'(Q(s',a')).\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)                                 # shape: (B)\n",
    "    # target_net(non_final_next_states), shape (B_non_final) :\n",
    "    #     Target DQN predicts Q values Q(s',a') for all possible actions a' (for non-final next state only)\n",
    "    # target_net(non_final_next_states).max(1)[0].detach(), shape (B_non_final)\n",
    "    #     max value of predicted Q values max_a'(Q(s',a'))\n",
    "    # next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach() :\n",
    "    #     update only values in next_state_values that correspond to non-final next states\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()   # shape: (B)\n",
    "    # expected_state_action_values :\n",
    "    #     target Q values = r + gamma * max_a'( Q(s',a') )\n",
    "    expected_state_action_values = reward_batch + (GAMMA * next_state_values)                  # shape: (B)\n",
    "    if DEBUG :\n",
    "        print(\"Target Q values (RHS) = r + gamma * max_a'( Q(s',a') )\")\n",
    "        print(\"= \", expected_state_action_values)\n",
    "\n",
    "    ##### Update Network Weights #####\n",
    "    # Compute the loss between predicted Q values (LHS) and target Q values (RHS).\n",
    "    # Mean Squared Error (MSE) is used as the loss function:\n",
    "    #     loss = (LHS - RHS)^2\n",
    "    loss = F.mse_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Update of DQN network weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        # Gradients are clipped within range [-1,1], to prevent exploding magnitude of gradients\n",
    "        # and failure of training.\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "    if DEBUG :\n",
    "        print(\"Loss: \", loss)\n",
    "        print(\"===== End of Experience Replay =====\")\n",
    "    # Return the computed loss value (for logging outside this function)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1584992814600,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "ZbwbFecDVQg1",
    "outputId": "e91cb3a5-94d7-4ea7-e044-e578cae812cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Start of Experience Replay =====\n",
      "State batch: \n",
      " tensor([[1., 1.],\n",
      "        [0., 0.]])\n",
      "Action batch: \n",
      " tensor([[1],\n",
      "        [0]])\n",
      "Reward batch: \n",
      " tensor([1., 0.])\n",
      "Locations of non-final next states: \n",
      " tensor([False,  True])\n",
      "-----\n",
      "Predicted Q values (LHS) = Q(s,a)\n",
      "=  tensor([[0.2026],\n",
      "        [0.1558]], grad_fn=<GatherBackward>)\n",
      "Target Q values (RHS) = r + gamma * max_a'( Q(s',a') )\n",
      "=  tensor([1.0000, 0.0788])\n",
      "Loss:  tensor(0.3209, grad_fn=<MseLossBackward>)\n",
      "===== End of Experience Replay =====\n",
      "\n",
      "Loss computed while updated the network weights:  tensor(0.3209, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Demo of Experience Replay \"\"\"\n",
    "# From previous demos:\n",
    "# policy_temp: test policy DQN\n",
    "# memory_temp: test memory buffer\n",
    "\n",
    "# Construct temporary target DQNs\n",
    "target_temp = DQN(in_dim=PARAMS[\"N_STATES\"], out_dim=PARAMS[\"N_ACTIONS\"])\n",
    "\n",
    "# Construct a temporary optimizer\n",
    "import torch.optim as optim\n",
    "optimizer_temp = optim.Adam(policy_temp.parameters(), lr=0.1)\n",
    "params_temp = {\"BATCH_SIZE\":2, \"GAMMA\": 0.99}\n",
    "\n",
    "# Demo of experience replay. \n",
    "# By setting DEBUG=True, values at intermediate steps will be displayed.\n",
    "# The returned value is the loss computed while updated the network weights\n",
    "loss_temp = experience_replay(policy_temp, target_temp, memory_temp, optimizer_temp, params_temp, DEBUG=True)\n",
    "print(\"\")\n",
    "print(\"Loss computed while updated the network weights: \", loss_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7k1tG8eqvmk"
   },
   "source": [
    "## Decaying Epsilon Greedy Exploration Policy\n",
    "\n",
    "Previously in Module 5, we have studied the topic of Exploration-Exploitation trade-off, and we have studied the use of Epsilon-greedy policy to guide the RL model to manage the balance between exploration and exploitation. In the previous example we have studied, we only used a constant exploration probability for all the time during training. In this study, we use a decaying exploration probability which starts at a large probability and decays over time. This allows the DQN model to explore more states at the beginning, and then attempt to refine its learning when training goes on. \n",
    "\n",
    "For simplicity, we only make epsilon to decay linearly over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1tPlgHLjpq84"
   },
   "outputs": [],
   "source": [
    "\"\"\" Epsilon Decay \"\"\"\n",
    "import math\n",
    "\n",
    "def get_epsilon(global_step, params):\n",
    "    \"\"\"\n",
    "    Input(s) :\n",
    "    - global_step: total number of steps taken so far from the beginning of training phase\n",
    "    - params: dictionary of global parameters, expecting values:\n",
    "              - params[\"EPS_START\"]: starting value of epsilon\n",
    "              - params[\"EPS_EN\"]: min value of epsilon\n",
    "              - params[\"EPS_DECAY_STEPS\"]: number of steps for epsilon to decay from EPS_START to EPS_END.\n",
    "    Output(s):\n",
    "    - epsilon value at global_step\n",
    "    \"\"\"\n",
    "    EPS_START = params[\"EPS_START\"]\n",
    "    EPS_END = params[\"EPS_END\"]\n",
    "    EPS_DECAY_STEPS = params[\"EPS_DECAY_STEPS\"]\n",
    "\n",
    "    if global_step <= EPS_DECAY_STEPS :\n",
    "        # When global_step <= EPS_DECAY_STEPS, epsilon is decaying linearly.\n",
    "        return EPS_START - global_step * (EPS_START - EPS_END)/EPS_DECAY_STEPS\n",
    "    else :\n",
    "        # Otherwise, epsilon stops decaying and stay at its minimum value EPS_END\n",
    "        return EPS_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 1227,
     "status": "ok",
     "timestamp": 1584992199640,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "aOnN9gVyrNqu",
    "outputId": "93dbc17e-530a-4042-92c0-e83b05f7204a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epsilon value:  1\n",
      "Minimum epsilon value:  0.01\n",
      "#Steps of (linear) decay:  10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Demonstration of Decaying value of Epsilon \"\"\"\n",
    "# Setting for demonstration of decaying epsilon value\n",
    "print(\"Starting epsilon value: \", PARAMS[\"EPS_START\"])\n",
    "print(\"Minimum epsilon value: \", PARAMS[\"EPS_END\"])\n",
    "print(\"#Steps of (linear) decay: \", PARAMS[\"EPS_DECAY_STEPS\"])\n",
    "\n",
    "# Let's observe for 20000 timesteps\n",
    "steps_temp = [ i for i in range(20000) ]\n",
    "\n",
    "# Get the epsilon value at each of the 20000 timesteps\n",
    "eps_temp = [ get_epsilon(step, PARAMS) for step in steps_temp ]\n",
    "\n",
    "# Plotting the trend of epsilon value\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Epsilon in Decaying Epsilon Greedy\")\n",
    "ax.plot(eps_temp)\n",
    "ax.set_xlabel(\"Timestep\")\n",
    "ax.set_ylabel(\"Epsilon\")\n",
    "ax.annotate('Until 10000th step:\\nLinear decay',\n",
    "            xy=(100.0, 225.0), xycoords='figure pixels')\n",
    "ax.annotate('After 10000th step:\\nMin value',\n",
    "            xy=(250.0, 75.0), xycoords='figure pixels')\n",
    "ax.axvline(10000, color='gray', alpha=0.5, dashes=(5,2,1,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKx1xMLZrF0l"
   },
   "source": [
    "At each step, we determine the action based on the epsilon value. Recall that in Epsilon-greedy policy:\n",
    "1. with probability epsilon: take random action (Exploration)\n",
    "2. otherwise: predict action with DQN model (Exploitation)\n",
    "\n",
    "__The implementation of Epsilon-greedy policy is left for you to finish.__\n",
    "\n",
    "__<u>Q2) Implement Epsilon-greedy policy according to the instructions provided below.</u>__\n",
    "\n",
    "The completed codes should pass the following test case, so that the following criterion (or criteria) is (are) fulfilled:\n",
    "\n",
    "C2.1) For ‚ÄúTest Case 2.1‚Äù, the 10 output actions should have DIFFERENT values (may have duplication, but not all the same)\n",
    "\n",
    "C2.2) For ‚ÄúTest Case 2.2‚Äù, the 10 output actions should have the SAME value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GlwpnHg_rFJs"
   },
   "outputs": [],
   "source": [
    "\"\"\" Epsilon-Greedy Policy \"\"\"\n",
    "def select_action(policy_net, state, epsilon, params):\n",
    "    \"\"\"\n",
    "    Input(s) :\n",
    "    - policy_net: Policy DQN for predicting Q values (for Exploitation)\n",
    "    - state: current state for predicting Q values (for Exploitation)\n",
    "    - epsilon: exploration probability\n",
    "    - params: dictionary of global parameters, expecting:\n",
    "              - params[\"N_ACTIONS\"]: number of possible actions\n",
    "    Output(s) :\n",
    "    - action: action to be taken, a tensor with type long and shape (1,1)\n",
    "    \"\"\"\n",
    "    if random.random() <= epsilon :\n",
    "        # With prob. epsilon,\n",
    "        # (Exploration) select random action.\n",
    "        device = next(policy_net.parameters()).device # Get computation device used by DQN model\n",
    "\n",
    "        # Your task:\n",
    "        # 1. Pick a random action \n",
    "        # 2. Prepare the action as a tensor with type long and shape (1,1)\n",
    "        # (Hint: you may consider random.randrange(...))\n",
    "        action = torch.tensor([[random.randrange(params[\"N_ACTIONS\"])]], device=device, dtype=torch.long)\n",
    "        \n",
    "\n",
    "    else :\n",
    "        # With prob. 1 - epsilon, \n",
    "        # (Exploitation) select action with max predicted Q-Values of current state.\n",
    "\n",
    "        # Your task:\n",
    "        # 1. Predict Q values of current state\n",
    "        # 2. Select action with greatest Q value\n",
    "        # 3. Prepare the action as a tensor with type long and shape (1,1)\n",
    "        # (Hint: policy_net(state) outputs the Q values for all actions)\n",
    "        with torch.no_grad():\n",
    "             action = policy_net(state).max(1)[1].view(1, 1)\n",
    "        \n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2f9Ad-gvyTkg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 2.1 - Exploration: \n",
      "Actions (Expected to have DIFFERENT values): \n",
      "[[0], [2], [2], [2], [2], [1], [0], [2], [1], [0]]\n",
      "-----\n",
      "Test Case 2.2 - Exploitation: \n",
      "Actions (Expected to have the SAME value for all 10 trials): \n",
      "[[1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Q2 Test Cases (Epsilon Greedy) \"\"\"\n",
    "#################################################\n",
    "# Please do not modify codes in this cell.      #\n",
    "# If the missing codes in the previous cell is  # \n",
    "# completed appropriately, you should be able   #\n",
    "# to execute this code cell without errors.     #\n",
    "#################################################\n",
    "\n",
    "s_temp = torch.zeros(1,2)  # use [[0,0]] as an test input state \n",
    "\n",
    "##### Test Case 2.1 - Exploration #####\n",
    "# Epsilon=1: Always explore (use random action)\n",
    "eps_explore = 1\n",
    "\n",
    "actions_explore = [ select_action(policy_temp, s_temp, eps_explore, PARAMS) \\\n",
    "                        for _ in range(10) ]\n",
    "print(\"Test Case 2.1 - Exploration: \")\n",
    "print(\"Actions (Expected to have DIFFERENT values): \")\n",
    "print(torch.cat(actions_explore).tolist())         # Convert to a list for clear display\n",
    "print(\"-----\")\n",
    "\n",
    "##### Test Case 2.2 - Exploitation #####\n",
    "# Epsilon=0: Always exploit (use model predicted action)\n",
    "eps_exploitation = 0\n",
    "\n",
    "# Using the same state, get the suggested action for 10 times\n",
    "actions_exploitation = [ select_action(policy_temp, s_temp, eps_exploitation, PARAMS) \\\n",
    "                        for _ in range(10) ]\n",
    "print(\"Test Case 2.2 - Exploitation: \")          \n",
    "print(\"Actions (Expected to have the SAME value for all 10 trials): \")\n",
    "print(torch.cat(actions_exploitation).tolist())    # Convert to a list for clear display\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzPU7mky4c5n"
   },
   "source": [
    "# Utility Functions\n",
    "\n",
    "Some utility functions are prepared to facilitate training of DQN model later. There is no missing part in this sub-section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jBypgnjD4cbc"
   },
   "outputs": [],
   "source": [
    "def preprocess_state(state, device=None) :\n",
    "    \"\"\"\n",
    "    To convert the state prepared by Gym and to a format\n",
    "    that is convenient for later processing \n",
    "    (see comments in function Experience replay)\n",
    "\n",
    "    Input(s) :\n",
    "    - state: state numpy array prepared by Gym envrionment\n",
    "    - device: computation device used for PyTorch tensors\n",
    "    \n",
    "    Output(s) :\n",
    "    - state: state as a PyTorch tensor with type float and\n",
    "             shape (1,2)\n",
    "    \"\"\"\n",
    "    #                                # The following values are default values.\n",
    "    #                                # variable type | value type | data shape\n",
    "    # input state                    # numpy.ndarray |   float64  | (2,)  \n",
    "    state = torch.from_numpy(state)  # torch.Tensor  |   double   | (2)  \n",
    "    state = state.float()            # torch.Tensor  |   float    | (2)  \n",
    "    state = state.unsqueeze(0)       # torch.Tensor  |   float    | (1,2)  \n",
    "\n",
    "    # Pass state tensor to the specified computation device \n",
    "    # (if None, the default device is used)\n",
    "    state = state.to(device)\n",
    "\n",
    "    return state\n",
    "\n",
    "def adjust_reward(reward, next_state) :\n",
    "    \"\"\"\n",
    "    Adjust reward based on the reward itself and the next state to \n",
    "    foster training of DQN model.\n",
    "    see: https://towardsdatascience.com/getting-started-with-reinforcement-learning-and-open-ai-gym-c289aca874f\n",
    "\n",
    "    Input(s) :\n",
    "    - reward: reward received from envrionment\n",
    "    - next_state: next state after action is taken\n",
    "\n",
    "    Output(s) :\n",
    "    - adjusted reward, as a integer value\n",
    "    \"\"\"\n",
    "    if next_state[0] >= 0.1:\n",
    "        reward += 10\n",
    "    elif next_state[0] >= 0.25:\n",
    "        reward += 20\n",
    "    elif next_state[0] >= 0.5:\n",
    "        reward += 100\n",
    "      \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEooHJrs3qRh"
   },
   "source": [
    "## Main Model Training Loop\n",
    "\n",
    "With the functions implemented above, we can start training the DQN model here. Most of the codes of the training loop are prepared, but there are 5 steps left unfinished. Your task is then to complete the 5 missing parts and the training codes work.\n",
    "\n",
    "__<u>Q3) Complete the 5 missing code sections according to the instructions provided below.</u>__\n",
    "\n",
    "The completed codes should pass the following test case, so that the following criterion (or criteria) is (are) fulfilled:\n",
    "\n",
    "C3.1) The training codes can be executed without errors\n",
    "\n",
    "C3.2) It can be shown that the performance of DQN model is improved after training, using the evaluation codes provided in the next sub-section (\"Training Results\").\n",
    "\n",
    "Hints:\n",
    "- Most of the sub-tasks below only require simple reuses of the appropriate function(s) defined above.\n",
    "- You may change the values of hyperparameters defined earlier. However, if all the codes in this checkpoint are completed appropriately, the default hyperparameter values should be good enough to train a DQN model that shows improved performance at the end of training (refer to sub-section \"Training Results\"). Therefore, it is __not suggested__ to modify the values for the purpose of completing this checkpoint, unless you have found it impossible to meet the requirements without doing so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 1114,
     "status": "ok",
     "timestamp": 1585004848116,
     "user": {
      "displayName": "Wing Hei Chan",
      "photoUrl": "",
      "userId": "00751424291180117802"
     },
     "user_tz": -480
    },
    "id": "EUkgidzU5753",
    "outputId": "1b25cfcb-3630-4361-f663-38f09f804fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "DQN Model Structure: \n",
      "DQN(\n",
      "  (lin1): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (lin2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (lin3): Linear(in_features=50, out_features=3, bias=True)\n",
      ")\n",
      "-----\n",
      "Memory Buffer Size:  33590\n",
      "Saved Transitions in Memory: 0 (Empty)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize DQN Model and Memory Buffer\"\"\"\n",
    "##### Deep Q Network Model #####\n",
    "# Computation device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "# Construct Policy/Target DQN model\n",
    "policy_net = DQN(in_dim=PARAMS[\"N_STATES\"], out_dim=PARAMS[\"N_ACTIONS\"]).to(device)\n",
    "target_net = DQN(in_dim=PARAMS[\"N_STATES\"], out_dim=PARAMS[\"N_ACTIONS\"]).to(device)\n",
    "# Initialize Target DQN by copying Policy DQN's initial weights\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "# Set target network to eval model. We do not train target network to modify its network weights\n",
    "target_net.eval()   \n",
    "print(\"DQN Model Structure: \")\n",
    "print(policy_net)\n",
    "\n",
    "# Optimizer (created for Policy DQN)\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=PARAMS[\"LR\"], weight_decay=PARAMS[\"LAMBDA\"])\n",
    "print(\"-----\")\n",
    "##### Memory Buffer for Experience Replay #####\n",
    "memory = ReplayMemory(PARAMS[\"MEM_BUFFER_SIZE\"])\n",
    "print(\"Memory Buffer Size: \", PARAMS[\"MEM_BUFFER_SIZE\"])\n",
    "print(\"Saved Transitions in Memory: {} (Empty)\".format(len(memory)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "P98OTOyl3mjE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Episode 0 =====\n",
      "Time:  0.8026466369628906\n",
      "Steps:  200\n",
      "Global Steps:  200\n",
      "Epsilon:  0.980299\n",
      "Reward:  -200.0\n",
      "Max x Pos: -0.3888222873210907\n",
      "====================\n",
      "===== Episode 100 =====\n",
      "Time:  63.878819704055786\n",
      "Steps:  200\n",
      "Global Steps:  20200\n",
      "Epsilon:  0.01\n",
      "Reward:  -200.0\n",
      "Max x Pos: -0.15649570524692535\n",
      "====================\n",
      "===== Episode 200 =====\n",
      "Time:  125.98089814186096\n",
      "Steps:  200\n",
      "Global Steps:  40200\n",
      "Epsilon:  0.01\n",
      "Reward:  -200.0\n",
      "Max x Pos: -0.3698579967021942\n",
      "====================\n",
      "===== Episode 300 =====\n",
      "Time:  187.663991689682\n",
      "Steps:  200\n",
      "Global Steps:  60200\n",
      "Epsilon:  0.01\n",
      "Reward:  -70.0\n",
      "Max x Pos: 0.14567941427230835\n",
      "====================\n",
      "===== Episode 400 =====\n",
      "Time:  249.17516040802002\n",
      "Steps:  200\n",
      "Global Steps:  80200\n",
      "Epsilon:  0.01\n",
      "Reward:  -200.0\n",
      "Max x Pos: -0.5270916223526001\n",
      "====================\n",
      "===== Episode 500 =====\n",
      "Time:  309.7316656112671\n",
      "Steps:  200\n",
      "Global Steps:  100200\n",
      "Epsilon:  0.01\n",
      "Reward:  -110.0\n",
      "Max x Pos: 0.12157847732305527\n",
      "====================\n",
      "===== Episode 600 =====\n",
      "Time:  370.33323907852173\n",
      "Steps:  200\n",
      "Global Steps:  120200\n",
      "Epsilon:  0.01\n",
      "Reward:  -10.0\n",
      "Max x Pos: 0.1978279948234558\n",
      "====================\n",
      "===== Episode 700 =====\n",
      "Time:  431.3839735984802\n",
      "Steps:  200\n",
      "Global Steps:  140187\n",
      "Epsilon:  0.01\n",
      "Reward:  10.0\n",
      "Max x Pos: 0.2767794728279114\n",
      "====================\n",
      "===== Episode 800 =====\n",
      "Time:  494.8669242858887\n",
      "Steps:  200\n",
      "Global Steps:  159916\n",
      "Epsilon:  0.01\n",
      "Reward:  40.0\n",
      "Max x Pos: 0.24413982033729553\n",
      "====================\n",
      "===== Episode 900 =====\n",
      "Time:  555.1693193912506\n",
      "Steps:  154\n",
      "Global Steps:  179762\n",
      "Epsilon:  0.01\n",
      "Reward:  76.0\n",
      "Max x Pos: 0.49510103464126587\n",
      "====================\n",
      "===== Episode 1000 =====\n",
      "Time:  612.9823610782623\n",
      "Steps:  168\n",
      "Global Steps:  198743\n",
      "Epsilon:  0.01\n",
      "Reward:  182.0\n",
      "Max x Pos: 0.48923707008361816\n",
      "====================\n",
      "===== Episode 1100 =====\n",
      "Time:  664.5819842815399\n",
      "Steps:  175\n",
      "Global Steps:  215694\n",
      "Epsilon:  0.01\n",
      "Reward:  -25.0\n",
      "Max x Pos: 0.48067358136177063\n",
      "====================\n",
      "===== Episode 1200 =====\n",
      "Time:  713.6433691978455\n",
      "Steps:  140\n",
      "Global Steps:  231794\n",
      "Epsilon:  0.01\n",
      "Reward:  10.0\n",
      "Max x Pos: 0.4993128180503845\n",
      "====================\n",
      "===== Episode 1300 =====\n",
      "Time:  757.9955215454102\n",
      "Steps:  193\n",
      "Global Steps:  246299\n",
      "Epsilon:  0.01\n",
      "Reward:  467.0\n",
      "Max x Pos: 0.46717214584350586\n",
      "====================\n",
      "===== Episode 1400 =====\n",
      "Time:  799.622142791748\n",
      "Steps:  114\n",
      "Global Steps:  260014\n",
      "Epsilon:  0.01\n",
      "Reward:  -4.0\n",
      "Max x Pos: 0.46966680884361267\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Main Training Loop \"\"\"\n",
    "from time import time\n",
    "\n",
    "# For logging\n",
    "global_steps = 0    # Counter of total #steps in training phase\n",
    "all_rewards = []    # Rewards received in each episode\n",
    "all_steps = []      # Steps taken in each episode\n",
    "all_max_xs = []     # Max x car position achieved in each episode\n",
    "\n",
    "##### 1. Initialization #####\n",
    "# policy_net: Policy DQN created and initialize above\n",
    "# target_net: Target DQN created and initialize above\n",
    "# memory: memory buffer created and initialize above\n",
    "\n",
    "##### 2. Loop for Episodes #####\n",
    "# Start of Training \n",
    "policy_net.train()         # Set Policy DQN model as train mode \n",
    "start_time = time() # Timer\n",
    "for episode in range(PARAMS[\"N_EPISODES\"]) :\n",
    "    if episode%100 == 0 :\n",
    "        print(\"===== Episode {} =====\".format(episode))\n",
    "    ##### 2.1. (Game Starts) Initialization of Mountain Car Environment #####\n",
    "    # Initialize the environment, get initial state\n",
    "    state = env.reset()\n",
    "    # Preprocess state \n",
    "    state = preprocess_state(state, device)\n",
    "    \n",
    "    ##### 2.2. Loop for Steps #####\n",
    "    # Logging for current episode\n",
    "    done = None            # To mark if current episode is done\n",
    "    episode_steps = 0      # Counter of steps taken in current episode\n",
    "    episode_reward = 0     # Sum of rewards received in current episode\n",
    "    episode_max_x = -100   # Record the max x car position achieved in current episode\n",
    "\n",
    "    # Loop till end of episode (done = True)\n",
    "    while not done :\n",
    "        ##### 2.2.1. (Epsilon-Greedy) Select Action #####\n",
    "        # ------------------------- Sub-Task 1 -------------------------\n",
    "        # Get epsilon value based on total number of steps taken during entire training phase\n",
    "        # Returned epsilon is a float value.\n",
    "        epsilon = get_epsilon(global_steps, PARAMS)\n",
    "\n",
    "        # ------------------------- End of Sub-Task 1 -------------------------\n",
    "\n",
    "        # ------------------------- Sub-Task 2 ------------------------- \n",
    "        # Select action with epsilon-greedy policy using Policy DQN.\n",
    "        # Returned action is a tensor with shape (1,1).\n",
    "        action = select_action(policy_net, state, epsilon, PARAMS)\n",
    "\n",
    "        # ------------------------- End of Sub-Task 2 -------------------------             \n",
    "        \n",
    "        ##### 2.2.2. Take Action #####\n",
    "        # ------------------------- Sub-Task 3 -------------------------\n",
    "        # Take action and get observations (next_state, rewards, done)\n",
    "        #next_state, reward, done ...\n",
    "        next_state, reward, done, _ = env.step(action[0, 0].item())\n",
    "       \n",
    "\n",
    "        # ------------------------- End of Sub-Task 3 -------------------------\n",
    "        # Adjust reward received to foster training of DQN model\n",
    "        reward = adjust_reward(reward, next_state)\n",
    "\n",
    "        ##### 2.2.3. (Experiment Replay) Store Transition #####\n",
    "        # Before storing (state, action, next_state, rewards) to memory buffer,\n",
    "        # convert the values into PyTorch tensors. \n",
    "        # state: converted to tensor from previous iteration\n",
    "        # action: prepared as tensor in function select_action(...)\n",
    "        # next_state:\n",
    "        if not done:\n",
    "            # If next state is not a terminal state, next_state will be memorized.\n",
    "            # Preprocess next_state before saving to memory.\n",
    "            next_state = preprocess_state(next_state, device)\n",
    "        else :\n",
    "            # If next state is a terminal state, mark next_state as None.\n",
    "            # Later during Experience Replay, the corresponding Q values will be \n",
    "            # set to 0s.\n",
    "            next_state = None\n",
    "        # reward: convert to tensor with shape (1)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        # ------------------------- Sub-Task 4 -------------------------\n",
    "        # Store the transition (s,a,r,s') in memory\n",
    "\n",
    "        memory.push(state, action, reward, next_state)\n",
    "\n",
    "\n",
    "        # ------------------------- End of Sub-Task 4 -------------------------\n",
    "\n",
    "        ##### 2.2.4. (Experiment Replay) Train DQN Model by sampling a Transitions Batch from Memory #####\n",
    "        # ------------------------- Sub-Task 5 -------------------------\n",
    "        # Note that update network weights of Policy DQN occurs here.\n",
    "        loss = experience_replay(policy_net, target_net, memory, optimizer, PARAMS, DEBUG=False)\n",
    "        #print(\"loss\", loss)\n",
    "\n",
    "        # ------------------------- End of Sub-Task 5 -------------------------\n",
    "\n",
    "        ##### 2.2.5 Update Target DQN network weights #####\n",
    "        # Only update Target DQN once in every TARGET_UPDATE_PER_STEPS steps in the entire training phase\n",
    "        if global_steps%PARAMS[\"TARGET_UPDATE_PER_STEPS\"] == 0 :\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        ##### 2.2.6 End of Epsiode #####\n",
    "        # Update training results at the end of episode.\n",
    "        state = next_state\n",
    "        global_steps += 1\n",
    "        episode_reward += reward.item()\n",
    "        episode_steps += 1\n",
    "        if next_state is not None and next_state[0,0] > episode_max_x :\n",
    "            episode_max_x = next_state[0,0].item()    \n",
    "        \n",
    "        # If too many steps are taken in this episode, forcibly stop this episode.\n",
    "        # This it to avoid the current episode ends up looping.\n",
    "        if episode_steps > PARAMS[\"MAX_STEP_PER_EPISODE\"] :\n",
    "            # However, this is not triggered in this example, because\n",
    "            # because PARAMS[\"MAX_STEP_PER_EPISODE\"] is set to be equal to \n",
    "            # the default max number of steps of Mountain Car environment.\n",
    "            # This checking is left here only as a remark of such scenario.\n",
    "            break\n",
    "\n",
    "    # Logging after an episode\n",
    "    end_time = time()\n",
    "    all_rewards.append(episode_reward)\n",
    "    all_steps.append(episode_steps)\n",
    "    all_max_xs.append(episode_max_x)\n",
    "    \n",
    "    # Print out logging messages\n",
    "    if episode%100 == 0 :\n",
    "        print(\"Time: \", end_time-start_time)\n",
    "        print(\"Steps: \", episode_steps)\n",
    "        print(\"Global Steps: \", global_steps)\n",
    "        print(\"Epsilon: \", epsilon)\n",
    "        print(\"Reward: \", episode_reward)\n",
    "        print(\"Max x Pos:\", episode_max_x)\n",
    "        print(\"====================\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9fr9rn6En5l"
   },
   "source": [
    "## Training Results\n",
    "\n",
    "One intuitive way to study how the DQN model learns during training is to plot the rewards received over episodes. The following figure shows the results of an attempt to train the DQN model above. Although there are signs showing the DQN model has learnt something (e.g., less frequent negative cumulative rewards near the end of training), they are hard to observe as the results are not stable and fluctuate in a large range.\n",
    "\n",
    "<center><img src='./figures/rewards.png' width='50%'/></center>\n",
    "<center>\n",
    "Rewards recorded from a trial of training DQN for \"Mountain Car\" problem during preparation of this notebook. \n",
    "<center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OYa0oLJt3ptS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Display Training Results \"\"\"\n",
    "################################################\n",
    "# The following codes may help you to evaluate # \n",
    "# the training results of your DQN model       #\n",
    "################################################\n",
    "\n",
    "# Plot rewards over episodes\n",
    "plt.plot(all_rewards) \n",
    "plt.title(\"Rewards\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHikkxI5Jrz6"
   },
   "source": [
    "This is not uncommon while training and evaluating RL models (especially RL models using neural networks, like DQL). There are many reasons causing such fluctuation of performance, such as different initial game states and insufficient learning of the model (try to think about other reasons!). Therefore, to obtain more comprehensible results, one often consider taking the moving average of the evaluation metrics, like rewards this time. The following figure shows an example of computing the moving average of rewards with a window size of 30 episodes. The trend of model performance that is shown by a less fluctuating line is more interpretable this time. \n",
    "\n",
    "<center><img src='./figures/rewards_ma.png' width='50%'/>\n",
    "<center>\n",
    "The moving average of rewards provides a more interpretable plot.\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-HwtQzebBZAJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Visualize Training Resutls with Moving Average of Rewards \"\"\"\n",
    "################################################\n",
    "# The following codes may help you to evaluate # \n",
    "# the training results of your DQN model       #\n",
    "################################################\n",
    "\n",
    "import pandas as pd\n",
    "# To compute moving average of rewards with a window of 30 episodes\n",
    "window = 30\n",
    "rewards_df = pd.DataFrame({'reward': all_rewards})\n",
    "rewards_ma = rewards_df.rolling(window=window).mean().values\n",
    "\n",
    "# Display results\n",
    "plt.title(\"Moving Average of Rewards\")\n",
    "plt.plot(all_rewards, color='blue', alpha=0.5, label=\"rewards\")\n",
    "plt.plot(rewards_ma, color='orange', label=\"rewards MA\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rkeM8mcEfqx"
   },
   "source": [
    "Another intuitive way is to simulate an episode of game play and let the DQN model play with it. Since visualization of game screen is easy, we can directly observe how the model behaves. The procedure of simulating game play is essentially the same as the training procedure, except that the DQN network weights are frozen and you may display the game screen on the fly. Therefore, the implementation will not be provided here, and this is left for your future practice.\n",
    "\n",
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAKKmJJbJ5sf"
   },
   "source": [
    "<a id=‚Äôs5‚Äô></a>\n",
    "# 5 Submission\n",
    "\n",
    "As instructed in section 4, your task in this checkpoint is to complete the missing codes. There are 3 sections of missing codes (under Q1-3). While completing the missing codes, there are some criteria to be fulfilled in each of the 3 sections. Therefore, to complete this checkpoint, you will need to submit this notebook, with:\n",
    "1. all missing codes completed (under Q1-3), and\n",
    "2. code execution results showing the completed codes fulfil their criteria. \n",
    "\n",
    "Please feel free to add code/text cells if you need, but please make notes about the modification/addition made.\n",
    "\n",
    "----- \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Checkpoint_Deep_RL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
